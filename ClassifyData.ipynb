{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVCm2JWeqxyFMnuQ9q1h17",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathanrowell/bot/blob/main/ClassifyData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgGDtQfU9psJ",
        "outputId": "e6c49418-a17a-40ba-d0bf-78f3a9990aeb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuUXAFUJ95La",
        "outputId": "c3cc70e2-4459-43ed-ccc6-6d456a510075"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Github/'\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "MGga-fG1Qo4A",
        "outputId": "78f0412a-0747-444a-d937-0b69a6194bb1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0c2cf451-b63a-4744-b44d-1909641c1921\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0c2cf451-b63a-4744-b44d-1909641c1921\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving complete_data.csv to complete_data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import sys\n",
        "#read data\n",
        "data = pd.read_csv(\"complete_data.csv\")\n",
        "df = pd.DataFrame(data)\n",
        "df.head()\n",
        "data = pd.get_dummies(df, columns=['RACE','GENDER','MARITAL'], prefix=['encoded','encoded2','encoded3'])\n",
        "print(data)\n",
        "print(data.shape)\n",
        "print(data.head)\n",
        "\n",
        "#creating X and Y test/trains\n",
        "X = data.drop(['EDULVL','FAMDHIST','ALCOHOL','SMOKE','LABEL'], axis=1)\n",
        "Y = data[\"LABEL\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y)\n",
        "\n",
        "#normalize data\n",
        "print(\"test\")\n",
        "print(X_test)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Set print options for numpy arrays\n",
        "np.set_printoptions(precision=2)  # Set the desired precision\n",
        "\n",
        "\n",
        "'''mean = X_train.mean()\n",
        "std = X_train.std()\n",
        "X_train -= mean\n",
        "X_train /= std\n",
        "X_test -= mean\n",
        "X_test /= std\n",
        "print(mean)\n",
        "print(std)'''\n",
        "plt.hist(X_train)\n",
        "plt.show()\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "#creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(X_train.shape[1],),activation = 'relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "print(X_test[40:50])\n",
        "print(y_test[40:50])\n",
        "print(model.summary())\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy','AUC'])\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "callback_a = ModelCheckpoint(filepath = 'best_model.hdf5', monitor = 'val_auc',\n",
        "                             save_best_only = True, save_weights_only = True)\n",
        "#callback_b = EarlyStopping(monitor='val_loss', mode = 'min', patience = 20, verbose = 1)\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=500,\n",
        "                    batch_size=10, callbacks = [callback_a])\n",
        "#,callback_b next to callback_a\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dn1iH3ehQzC4",
        "outputId": "445ef219-4310-474f-8553-9b5abc451c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        SEQN  AGE  FPIR  EDULVL    BMI  WAIST FAMDHIST     ALCOHOL  MVPA  \\\n",
            "0          5   49  5.00    high  29.10   99.9       no       heavy    60   \n",
            "1         12   37  4.93    high  30.62  112.8      yes  occasional     0   \n",
            "2         15   38  4.52    high  26.68   86.7       no       heavy   165   \n",
            "3         20   23  3.03     low  23.68   81.0      yes    moderate     0   \n",
            "4         25   42  1.77    high  37.60  114.5       no       heavy     0   \n",
            "...      ...  ...   ...     ...    ...    ...      ...         ...   ...   \n",
            "13359  93656   75  3.40  medium  37.90  122.0      yes  abstainers     0   \n",
            "13360  93663   43  1.07     low  24.10   94.6       no  occasional     0   \n",
            "13361  93664   39  4.93  medium  26.00   92.5       no  occasional     0   \n",
            "13362  93677   34  1.76    high  22.20   83.3       no    moderate    20   \n",
            "13363  93695   76  1.43  medium  21.50   95.0       no  abstainers     0   \n",
            "\n",
            "             SYST  ...  encoded_4 encoded_5  encoded2_1  encoded2_2  \\\n",
            "0      122.000000  ...          0         0           1           0   \n",
            "1      176.666667  ...          0         0           1           0   \n",
            "2      108.000000  ...          0         0           0           1   \n",
            "3      102.666667  ...          0         0           0           1   \n",
            "4      119.333333  ...          0         0           0           1   \n",
            "...           ...  ...        ...       ...         ...         ...   \n",
            "13359  137.333333  ...          0         0           0           1   \n",
            "13360  114.000000  ...          0         0           1           0   \n",
            "13361  166.666667  ...          0         0           1           0   \n",
            "13362  113.333333  ...          0         0           0           1   \n",
            "13363  111.333333  ...          0         0           0           1   \n",
            "\n",
            "       encoded3_1  encoded3_2  encoded3_3  encoded3_4  encoded3_5  encoded3_6  \n",
            "0               1           0           0           0           0           0  \n",
            "1               0           0           0           0           1           0  \n",
            "2               0           0           1           0           0           0  \n",
            "3               0           0           0           0           0           1  \n",
            "4               1           0           0           0           0           0  \n",
            "...           ...         ...         ...         ...         ...         ...  \n",
            "13359           0           1           0           0           0           0  \n",
            "13360           1           0           0           0           0           0  \n",
            "13361           1           0           0           0           0           0  \n",
            "13362           0           0           0           0           1           0  \n",
            "13363           0           1           0           0           0           0  \n",
            "\n",
            "[13364 rows x 27 columns]\n",
            "(13364, 27)\n",
            "<bound method NDFrame.head of         SEQN  AGE  FPIR  EDULVL    BMI  WAIST FAMDHIST     ALCOHOL  MVPA  \\\n",
            "0          5   49  5.00    high  29.10   99.9       no       heavy    60   \n",
            "1         12   37  4.93    high  30.62  112.8      yes  occasional     0   \n",
            "2         15   38  4.52    high  26.68   86.7       no       heavy   165   \n",
            "3         20   23  3.03     low  23.68   81.0      yes    moderate     0   \n",
            "4         25   42  1.77    high  37.60  114.5       no       heavy     0   \n",
            "...      ...  ...   ...     ...    ...    ...      ...         ...   ...   \n",
            "13359  93656   75  3.40  medium  37.90  122.0      yes  abstainers     0   \n",
            "13360  93663   43  1.07     low  24.10   94.6       no  occasional     0   \n",
            "13361  93664   39  4.93  medium  26.00   92.5       no  occasional     0   \n",
            "13362  93677   34  1.76    high  22.20   83.3       no    moderate    20   \n",
            "13363  93695   76  1.43  medium  21.50   95.0       no  abstainers     0   \n",
            "\n",
            "             SYST  ...  encoded_4 encoded_5  encoded2_1  encoded2_2  \\\n",
            "0      122.000000  ...          0         0           1           0   \n",
            "1      176.666667  ...          0         0           1           0   \n",
            "2      108.000000  ...          0         0           0           1   \n",
            "3      102.666667  ...          0         0           0           1   \n",
            "4      119.333333  ...          0         0           0           1   \n",
            "...           ...  ...        ...       ...         ...         ...   \n",
            "13359  137.333333  ...          0         0           0           1   \n",
            "13360  114.000000  ...          0         0           1           0   \n",
            "13361  166.666667  ...          0         0           1           0   \n",
            "13362  113.333333  ...          0         0           0           1   \n",
            "13363  111.333333  ...          0         0           0           1   \n",
            "\n",
            "       encoded3_1  encoded3_2  encoded3_3  encoded3_4  encoded3_5  encoded3_6  \n",
            "0               1           0           0           0           0           0  \n",
            "1               0           0           0           0           1           0  \n",
            "2               0           0           1           0           0           0  \n",
            "3               0           0           0           0           0           1  \n",
            "4               1           0           0           0           0           0  \n",
            "...           ...         ...         ...         ...         ...         ...  \n",
            "13359           0           1           0           0           0           0  \n",
            "13360           1           0           0           0           0           0  \n",
            "13361           1           0           0           0           0           0  \n",
            "13362           0           0           0           0           1           0  \n",
            "13363           0           1           0           0           0           0  \n",
            "\n",
            "[13364 rows x 27 columns]>\n",
            "test\n",
            "        SEQN  AGE  FPIR    BMI  WAIST  MVPA        SYST       DIAS  \\\n",
            "758     6533   30  5.00  22.88   82.6    65   96.000000  59.333333   \n",
            "8761   61338   58  5.00  23.81   84.6     0  125.333333  71.333333   \n",
            "11569  81530   73  3.81  22.30   91.5     0  150.666667  63.333333   \n",
            "5014   37740   29  2.33  30.15  101.3     0  128.000000  74.000000   \n",
            "10487  74751   53  1.64  37.10  108.0     0  141.333333  77.333333   \n",
            "...      ...  ...   ...    ...    ...   ...         ...        ...   \n",
            "10926  77540   43  5.00  25.90   94.0     0  123.333333  71.333333   \n",
            "13107  91899   48  5.00  21.00   82.0   300  114.666667  70.666667   \n",
            "5748   42787   35  1.86  27.34   84.8   240  110.000000  68.666667   \n",
            "1320   11068   29  3.31  30.37  110.8    90  124.000000  74.000000   \n",
            "1466   12217   84  1.11  24.08   87.6     0  154.000000  82.666667   \n",
            "\n",
            "            SMPLWGT  encoded_1  ...  encoded_4  encoded_5  encoded2_1  \\\n",
            "758     3536.445397          0  ...          0          0           0   \n",
            "8761    1508.727082          1  ...          0          0           1   \n",
            "11569   5723.695896          0  ...          0          1           0   \n",
            "5014    2577.325204          0  ...          1          0           1   \n",
            "10487   2239.208669          0  ...          1          0           0   \n",
            "...             ...        ...  ...        ...        ...         ...   \n",
            "10926   1537.997389          0  ...          0          1           1   \n",
            "13107   1857.713422          0  ...          0          1           0   \n",
            "5748   11399.716701          0  ...          0          0           0   \n",
            "1320    2751.745865          0  ...          0          0           1   \n",
            "1466     740.693173          0  ...          0          0           0   \n",
            "\n",
            "       encoded2_2  encoded3_1  encoded3_2  encoded3_3  encoded3_4  encoded3_5  \\\n",
            "758             1           1           0           0           0           0   \n",
            "8761            0           1           0           0           0           0   \n",
            "11569           1           1           0           0           0           0   \n",
            "5014            0           1           0           0           0           0   \n",
            "10487           1           1           0           0           0           0   \n",
            "...           ...         ...         ...         ...         ...         ...   \n",
            "10926           0           1           0           0           0           0   \n",
            "13107           1           1           0           0           0           0   \n",
            "5748            1           0           0           0           0           1   \n",
            "1320            0           1           0           0           0           0   \n",
            "1466            1           0           1           0           0           0   \n",
            "\n",
            "       encoded3_6  \n",
            "758             0  \n",
            "8761            0  \n",
            "11569           0  \n",
            "5014            0  \n",
            "10487           0  \n",
            "...           ...  \n",
            "10926           0  \n",
            "13107           0  \n",
            "5748            0  \n",
            "1320            0  \n",
            "1466            0  \n",
            "\n",
            "[3341 rows x 22 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.13 -0.26  1.3   0.17  0.35 -0.64  0.22  1.22  2.54 -0.47 -0.29  1.04\n",
            "  -0.48 -0.29  1.02 -1.02  0.93 -0.28 -0.33 -0.18 -0.47 -0.29]\n",
            " [-1.33  0.3   1.4   1.6   0.27  0.97 -0.28  0.5  -0.42 -0.47 -0.29  1.04\n",
            "  -0.48 -0.29 -0.98  0.98  0.93 -0.28 -0.33 -0.18 -0.47 -0.29]\n",
            " [-0.87 -1.05 -0.21 -0.61 -0.24 -0.1  -0.35  0.65 -0.52 -0.47 -0.29  1.04\n",
            "  -0.48 -0.29  1.02 -1.02 -1.08 -0.28 -0.33 -0.18 -0.47  3.44]\n",
            " [-0.27 -1.44  0.01 -1.28 -1.09 -0.24 -0.03  1.12  1.15 -0.47 -0.29  1.04\n",
            "  -0.48 -0.29  1.02 -1.02 -1.08 -0.28 -0.33 -0.18  2.14 -0.29]\n",
            " [ 0.63  0.13 -1.1   1.52  0.73 -0.1  -0.68  0.24 -0.31 -0.47  3.49 -0.97\n",
            "  -0.48 -0.29 -0.98  0.98 -1.08 -0.28  3.   -0.18 -0.47 -0.29]\n",
            " [ 0.82  1.03 -0.58 -0.96 -0.87 -0.64  0.12 -0.85 -0.69 -0.47  3.49 -0.97\n",
            "  -0.48 -0.29 -0.98  0.98 -1.08 -0.28 -0.33 -0.18  2.14 -0.29]\n",
            " [-0.43  0.58 -0.49  0.53  0.7   1.78  1.2   0.03  0.39 -0.47 -0.29  1.04\n",
            "  -0.48 -0.29 -0.98  0.98  0.93 -0.28 -0.33 -0.18 -0.47 -0.29]\n",
            " [-0.67  0.02 -0.21 -0.45 -0.49 -0.64 -0.35 -0.18 -0.82 -0.47 -0.29 -0.97\n",
            "   2.08 -0.29  1.02 -1.02 -1.08 -0.28 -0.33 -0.18 -0.47  3.44]\n",
            " [ 1.17  0.3   1.4  -0.36 -0.51 -0.37  0.3   1.58  3.18 -0.47 -0.29  1.04\n",
            "  -0.48 -0.29  1.02 -1.02  0.93 -0.28 -0.33 -0.18 -0.47 -0.29]\n",
            " [ 0.23 -0.94  1.37  0.35  0.35 -0.55 -0.71  0.39 -0.16  2.15 -0.29 -0.97\n",
            "  -0.48 -0.29  1.02 -1.02  0.93 -0.28 -0.33 -0.18 -0.47 -0.29]]\n",
            "[[0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 64)                1472      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,684\n",
            "Trainable params: 3,684\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.9705 - accuracy: 0.5675 - auc: 0.8298 - val_loss: 0.9507 - val_accuracy: 0.5741 - val_auc: 0.8358\n",
            "Epoch 2/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.9173 - accuracy: 0.5920 - auc: 0.8479 - val_loss: 0.9451 - val_accuracy: 0.5738 - val_auc: 0.8375\n",
            "Epoch 3/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.9074 - accuracy: 0.5978 - auc: 0.8513 - val_loss: 0.9387 - val_accuracy: 0.5765 - val_auc: 0.8401\n",
            "Epoch 4/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.9011 - accuracy: 0.6013 - auc: 0.8532 - val_loss: 0.9431 - val_accuracy: 0.5693 - val_auc: 0.8371\n",
            "Epoch 5/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8954 - accuracy: 0.6013 - auc: 0.8552 - val_loss: 0.9461 - val_accuracy: 0.5732 - val_auc: 0.8376\n",
            "Epoch 6/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8915 - accuracy: 0.6079 - auc: 0.8567 - val_loss: 0.9484 - val_accuracy: 0.5654 - val_auc: 0.8350\n",
            "Epoch 7/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.8869 - accuracy: 0.6106 - auc: 0.8583 - val_loss: 0.9499 - val_accuracy: 0.5663 - val_auc: 0.8350\n",
            "Epoch 8/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.8820 - accuracy: 0.6090 - auc: 0.8597 - val_loss: 0.9509 - val_accuracy: 0.5669 - val_auc: 0.8356\n",
            "Epoch 9/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8786 - accuracy: 0.6136 - auc: 0.8613 - val_loss: 0.9486 - val_accuracy: 0.5672 - val_auc: 0.8370\n",
            "Epoch 10/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8751 - accuracy: 0.6150 - auc: 0.8622 - val_loss: 0.9561 - val_accuracy: 0.5660 - val_auc: 0.8366\n",
            "Epoch 11/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8709 - accuracy: 0.6185 - auc: 0.8637 - val_loss: 0.9512 - val_accuracy: 0.5666 - val_auc: 0.8364\n",
            "Epoch 12/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.8665 - accuracy: 0.6216 - auc: 0.8653 - val_loss: 0.9565 - val_accuracy: 0.5648 - val_auc: 0.8347\n",
            "Epoch 13/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.8633 - accuracy: 0.6199 - auc: 0.8659 - val_loss: 0.9613 - val_accuracy: 0.5690 - val_auc: 0.8358\n",
            "Epoch 14/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.8599 - accuracy: 0.6235 - auc: 0.8672 - val_loss: 0.9685 - val_accuracy: 0.5654 - val_auc: 0.8327\n",
            "Epoch 15/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8569 - accuracy: 0.6223 - auc: 0.8678 - val_loss: 0.9598 - val_accuracy: 0.5567 - val_auc: 0.8329\n",
            "Epoch 16/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.8515 - accuracy: 0.6229 - auc: 0.8699 - val_loss: 0.9755 - val_accuracy: 0.5582 - val_auc: 0.8312\n",
            "Epoch 17/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.8493 - accuracy: 0.6287 - auc: 0.8705 - val_loss: 0.9636 - val_accuracy: 0.5675 - val_auc: 0.8349\n",
            "Epoch 18/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.8449 - accuracy: 0.6312 - auc: 0.8721 - val_loss: 0.9827 - val_accuracy: 0.5609 - val_auc: 0.8309\n",
            "Epoch 19/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.8422 - accuracy: 0.6339 - auc: 0.8727 - val_loss: 0.9765 - val_accuracy: 0.5549 - val_auc: 0.8304\n",
            "Epoch 20/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.8368 - accuracy: 0.6343 - auc: 0.8743 - val_loss: 0.9824 - val_accuracy: 0.5627 - val_auc: 0.8311\n",
            "Epoch 21/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.8342 - accuracy: 0.6331 - auc: 0.8750 - val_loss: 0.9834 - val_accuracy: 0.5597 - val_auc: 0.8310\n",
            "Epoch 22/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.8315 - accuracy: 0.6364 - auc: 0.8759 - val_loss: 0.9870 - val_accuracy: 0.5537 - val_auc: 0.8288\n",
            "Epoch 23/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8250 - accuracy: 0.6393 - auc: 0.8779 - val_loss: 0.9932 - val_accuracy: 0.5579 - val_auc: 0.8287\n",
            "Epoch 24/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8221 - accuracy: 0.6401 - auc: 0.8788 - val_loss: 0.9927 - val_accuracy: 0.5501 - val_auc: 0.8264\n",
            "Epoch 25/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8181 - accuracy: 0.6432 - auc: 0.8800 - val_loss: 1.0062 - val_accuracy: 0.5516 - val_auc: 0.8232\n",
            "Epoch 26/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.8160 - accuracy: 0.6460 - auc: 0.8807 - val_loss: 1.0049 - val_accuracy: 0.5516 - val_auc: 0.8254\n",
            "Epoch 27/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.8146 - accuracy: 0.6459 - auc: 0.8811 - val_loss: 1.0035 - val_accuracy: 0.5474 - val_auc: 0.8237\n",
            "Epoch 28/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8105 - accuracy: 0.6441 - auc: 0.8822 - val_loss: 1.0177 - val_accuracy: 0.5519 - val_auc: 0.8218\n",
            "Epoch 29/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8045 - accuracy: 0.6532 - auc: 0.8843 - val_loss: 1.0145 - val_accuracy: 0.5418 - val_auc: 0.8213\n",
            "Epoch 30/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8033 - accuracy: 0.6505 - auc: 0.8843 - val_loss: 1.0317 - val_accuracy: 0.5447 - val_auc: 0.8181\n",
            "Epoch 31/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.8014 - accuracy: 0.6526 - auc: 0.8848 - val_loss: 1.0227 - val_accuracy: 0.5465 - val_auc: 0.8217\n",
            "Epoch 32/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7976 - accuracy: 0.6507 - auc: 0.8859 - val_loss: 1.0325 - val_accuracy: 0.5453 - val_auc: 0.8223\n",
            "Epoch 33/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7939 - accuracy: 0.6511 - auc: 0.8870 - val_loss: 1.0461 - val_accuracy: 0.5564 - val_auc: 0.8222\n",
            "Epoch 34/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7919 - accuracy: 0.6577 - auc: 0.8878 - val_loss: 1.0324 - val_accuracy: 0.5435 - val_auc: 0.8192\n",
            "Epoch 35/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7900 - accuracy: 0.6569 - auc: 0.8882 - val_loss: 1.0467 - val_accuracy: 0.5522 - val_auc: 0.8201\n",
            "Epoch 36/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7864 - accuracy: 0.6584 - auc: 0.8892 - val_loss: 1.0435 - val_accuracy: 0.5531 - val_auc: 0.8205\n",
            "Epoch 37/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7834 - accuracy: 0.6555 - auc: 0.8899 - val_loss: 1.0469 - val_accuracy: 0.5495 - val_auc: 0.8185\n",
            "Epoch 38/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7820 - accuracy: 0.6574 - auc: 0.8903 - val_loss: 1.0469 - val_accuracy: 0.5468 - val_auc: 0.8204\n",
            "Epoch 39/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7789 - accuracy: 0.6608 - auc: 0.8912 - val_loss: 1.0639 - val_accuracy: 0.5412 - val_auc: 0.8101\n",
            "Epoch 40/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7750 - accuracy: 0.6643 - auc: 0.8924 - val_loss: 1.0748 - val_accuracy: 0.5477 - val_auc: 0.8177\n",
            "Epoch 41/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7732 - accuracy: 0.6666 - auc: 0.8929 - val_loss: 1.0672 - val_accuracy: 0.5573 - val_auc: 0.8190\n",
            "Epoch 42/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7711 - accuracy: 0.6693 - auc: 0.8936 - val_loss: 1.0699 - val_accuracy: 0.5415 - val_auc: 0.8165\n",
            "Epoch 43/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7687 - accuracy: 0.6698 - auc: 0.8943 - val_loss: 1.0843 - val_accuracy: 0.5385 - val_auc: 0.8137\n",
            "Epoch 44/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7659 - accuracy: 0.6654 - auc: 0.8948 - val_loss: 1.0854 - val_accuracy: 0.5459 - val_auc: 0.8175\n",
            "Epoch 45/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7643 - accuracy: 0.6683 - auc: 0.8953 - val_loss: 1.0912 - val_accuracy: 0.5403 - val_auc: 0.8135\n",
            "Epoch 46/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.7634 - accuracy: 0.6684 - auc: 0.8955 - val_loss: 1.0934 - val_accuracy: 0.5450 - val_auc: 0.8135\n",
            "Epoch 47/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7612 - accuracy: 0.6690 - auc: 0.8961 - val_loss: 1.0901 - val_accuracy: 0.5480 - val_auc: 0.8162\n",
            "Epoch 48/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7560 - accuracy: 0.6770 - auc: 0.8974 - val_loss: 1.0919 - val_accuracy: 0.5349 - val_auc: 0.8101\n",
            "Epoch 49/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7570 - accuracy: 0.6735 - auc: 0.8972 - val_loss: 1.0973 - val_accuracy: 0.5453 - val_auc: 0.8121\n",
            "Epoch 50/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7561 - accuracy: 0.6695 - auc: 0.8974 - val_loss: 1.1054 - val_accuracy: 0.5337 - val_auc: 0.8098\n",
            "Epoch 51/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7511 - accuracy: 0.6717 - auc: 0.8988 - val_loss: 1.1116 - val_accuracy: 0.5447 - val_auc: 0.8128\n",
            "Epoch 52/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7504 - accuracy: 0.6698 - auc: 0.8988 - val_loss: 1.1229 - val_accuracy: 0.5471 - val_auc: 0.8112\n",
            "Epoch 53/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7480 - accuracy: 0.6777 - auc: 0.8998 - val_loss: 1.1297 - val_accuracy: 0.5540 - val_auc: 0.8152\n",
            "Epoch 54/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.7454 - accuracy: 0.6788 - auc: 0.9003 - val_loss: 1.1334 - val_accuracy: 0.5373 - val_auc: 0.8095\n",
            "Epoch 55/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7457 - accuracy: 0.6758 - auc: 0.9001 - val_loss: 1.1265 - val_accuracy: 0.5382 - val_auc: 0.8083\n",
            "Epoch 56/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.7422 - accuracy: 0.6787 - auc: 0.9010 - val_loss: 1.1397 - val_accuracy: 0.5331 - val_auc: 0.8063\n",
            "Epoch 57/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7423 - accuracy: 0.6778 - auc: 0.9010 - val_loss: 1.1391 - val_accuracy: 0.5412 - val_auc: 0.8093\n",
            "Epoch 58/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7378 - accuracy: 0.6799 - auc: 0.9023 - val_loss: 1.1483 - val_accuracy: 0.5352 - val_auc: 0.8075\n",
            "Epoch 59/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7374 - accuracy: 0.6825 - auc: 0.9026 - val_loss: 1.1485 - val_accuracy: 0.5367 - val_auc: 0.8048\n",
            "Epoch 60/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.7346 - accuracy: 0.6847 - auc: 0.9032 - val_loss: 1.1450 - val_accuracy: 0.5385 - val_auc: 0.8067\n",
            "Epoch 61/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7338 - accuracy: 0.6801 - auc: 0.9032 - val_loss: 1.1587 - val_accuracy: 0.5379 - val_auc: 0.8115\n",
            "Epoch 62/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7309 - accuracy: 0.6907 - auc: 0.9043 - val_loss: 1.1593 - val_accuracy: 0.5388 - val_auc: 0.8047\n",
            "Epoch 63/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7281 - accuracy: 0.6888 - auc: 0.9050 - val_loss: 1.1590 - val_accuracy: 0.5403 - val_auc: 0.8067\n",
            "Epoch 64/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7295 - accuracy: 0.6829 - auc: 0.9045 - val_loss: 1.1704 - val_accuracy: 0.5391 - val_auc: 0.8079\n",
            "Epoch 65/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7244 - accuracy: 0.6875 - auc: 0.9057 - val_loss: 1.1745 - val_accuracy: 0.5415 - val_auc: 0.8073\n",
            "Epoch 66/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7261 - accuracy: 0.6880 - auc: 0.9055 - val_loss: 1.1717 - val_accuracy: 0.5385 - val_auc: 0.8044\n",
            "Epoch 67/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7240 - accuracy: 0.6834 - auc: 0.9058 - val_loss: 1.1952 - val_accuracy: 0.5379 - val_auc: 0.8053\n",
            "Epoch 68/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7223 - accuracy: 0.6861 - auc: 0.9062 - val_loss: 1.1802 - val_accuracy: 0.5256 - val_auc: 0.8033\n",
            "Epoch 69/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7186 - accuracy: 0.6904 - auc: 0.9074 - val_loss: 1.2041 - val_accuracy: 0.5223 - val_auc: 0.7941\n",
            "Epoch 70/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7190 - accuracy: 0.6873 - auc: 0.9070 - val_loss: 1.1999 - val_accuracy: 0.5352 - val_auc: 0.8060\n",
            "Epoch 71/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7173 - accuracy: 0.6917 - auc: 0.9077 - val_loss: 1.2059 - val_accuracy: 0.5334 - val_auc: 0.8013\n",
            "Epoch 72/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7161 - accuracy: 0.6904 - auc: 0.9079 - val_loss: 1.2060 - val_accuracy: 0.5424 - val_auc: 0.8086\n",
            "Epoch 73/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7138 - accuracy: 0.6923 - auc: 0.9086 - val_loss: 1.2088 - val_accuracy: 0.5340 - val_auc: 0.8055\n",
            "Epoch 74/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7131 - accuracy: 0.6914 - auc: 0.9087 - val_loss: 1.2002 - val_accuracy: 0.5376 - val_auc: 0.8050\n",
            "Epoch 75/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7082 - accuracy: 0.6973 - auc: 0.9102 - val_loss: 1.2050 - val_accuracy: 0.5433 - val_auc: 0.8075\n",
            "Epoch 76/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7097 - accuracy: 0.6912 - auc: 0.9094 - val_loss: 1.2100 - val_accuracy: 0.5382 - val_auc: 0.8069\n",
            "Epoch 77/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7066 - accuracy: 0.6988 - auc: 0.9105 - val_loss: 1.2129 - val_accuracy: 0.5370 - val_auc: 0.8047\n",
            "Epoch 78/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7082 - accuracy: 0.6936 - auc: 0.9101 - val_loss: 1.2075 - val_accuracy: 0.5364 - val_auc: 0.8021\n",
            "Epoch 79/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7051 - accuracy: 0.6912 - auc: 0.9105 - val_loss: 1.2332 - val_accuracy: 0.5307 - val_auc: 0.8000\n",
            "Epoch 80/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7042 - accuracy: 0.6931 - auc: 0.9109 - val_loss: 1.2220 - val_accuracy: 0.5382 - val_auc: 0.8026\n",
            "Epoch 81/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7034 - accuracy: 0.6938 - auc: 0.9110 - val_loss: 1.2482 - val_accuracy: 0.5394 - val_auc: 0.8035\n",
            "Epoch 82/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.7021 - accuracy: 0.6957 - auc: 0.9114 - val_loss: 1.2386 - val_accuracy: 0.5328 - val_auc: 0.7997\n",
            "Epoch 83/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.7013 - accuracy: 0.7014 - auc: 0.9118 - val_loss: 1.2439 - val_accuracy: 0.5235 - val_auc: 0.7989\n",
            "Epoch 84/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6984 - accuracy: 0.6999 - auc: 0.9124 - val_loss: 1.2352 - val_accuracy: 0.5465 - val_auc: 0.8059\n",
            "Epoch 85/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6989 - accuracy: 0.6997 - auc: 0.9122 - val_loss: 1.2361 - val_accuracy: 0.5331 - val_auc: 0.8020\n",
            "Epoch 86/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6975 - accuracy: 0.6964 - auc: 0.9125 - val_loss: 1.2430 - val_accuracy: 0.5388 - val_auc: 0.8008\n",
            "Epoch 87/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6952 - accuracy: 0.7004 - auc: 0.9134 - val_loss: 1.2479 - val_accuracy: 0.5280 - val_auc: 0.7966\n",
            "Epoch 88/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6969 - accuracy: 0.6990 - auc: 0.9127 - val_loss: 1.2755 - val_accuracy: 0.5271 - val_auc: 0.7984\n",
            "Epoch 89/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6930 - accuracy: 0.7013 - auc: 0.9139 - val_loss: 1.2747 - val_accuracy: 0.5295 - val_auc: 0.7989\n",
            "Epoch 90/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6924 - accuracy: 0.7012 - auc: 0.9138 - val_loss: 1.2630 - val_accuracy: 0.5391 - val_auc: 0.8013\n",
            "Epoch 91/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6907 - accuracy: 0.7020 - auc: 0.9140 - val_loss: 1.2509 - val_accuracy: 0.5358 - val_auc: 0.8037\n",
            "Epoch 92/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6888 - accuracy: 0.7062 - auc: 0.9149 - val_loss: 1.2526 - val_accuracy: 0.5379 - val_auc: 0.8028\n",
            "Epoch 93/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6868 - accuracy: 0.7044 - auc: 0.9153 - val_loss: 1.2703 - val_accuracy: 0.5277 - val_auc: 0.7953\n",
            "Epoch 94/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6895 - accuracy: 0.7015 - auc: 0.9145 - val_loss: 1.2762 - val_accuracy: 0.5370 - val_auc: 0.8040\n",
            "Epoch 95/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6858 - accuracy: 0.7040 - auc: 0.9154 - val_loss: 1.2741 - val_accuracy: 0.5406 - val_auc: 0.8006\n",
            "Epoch 96/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6857 - accuracy: 0.7021 - auc: 0.9157 - val_loss: 1.2861 - val_accuracy: 0.5394 - val_auc: 0.8006\n",
            "Epoch 97/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6851 - accuracy: 0.7047 - auc: 0.9158 - val_loss: 1.2751 - val_accuracy: 0.5406 - val_auc: 0.8013\n",
            "Epoch 98/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6837 - accuracy: 0.7092 - auc: 0.9161 - val_loss: 1.2854 - val_accuracy: 0.5361 - val_auc: 0.8009\n",
            "Epoch 99/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6836 - accuracy: 0.7057 - auc: 0.9160 - val_loss: 1.2897 - val_accuracy: 0.5346 - val_auc: 0.8028\n",
            "Epoch 100/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.7089 - auc: 0.9169 - val_loss: 1.3014 - val_accuracy: 0.5256 - val_auc: 0.7953\n",
            "Epoch 101/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6805 - accuracy: 0.7092 - auc: 0.9169 - val_loss: 1.3020 - val_accuracy: 0.5391 - val_auc: 0.7992\n",
            "Epoch 102/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.7092 - auc: 0.9171 - val_loss: 1.2889 - val_accuracy: 0.5450 - val_auc: 0.8037\n",
            "Epoch 103/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6800 - accuracy: 0.7084 - auc: 0.9170 - val_loss: 1.2936 - val_accuracy: 0.5346 - val_auc: 0.8010\n",
            "Epoch 104/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6788 - accuracy: 0.7067 - auc: 0.9171 - val_loss: 1.2952 - val_accuracy: 0.5295 - val_auc: 0.7962\n",
            "Epoch 105/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6741 - accuracy: 0.7134 - auc: 0.9185 - val_loss: 1.3097 - val_accuracy: 0.5394 - val_auc: 0.8010\n",
            "Epoch 106/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6742 - accuracy: 0.7137 - auc: 0.9188 - val_loss: 1.3328 - val_accuracy: 0.5358 - val_auc: 0.7947\n",
            "Epoch 107/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.7093 - auc: 0.9174 - val_loss: 1.3060 - val_accuracy: 0.5352 - val_auc: 0.7986\n",
            "Epoch 108/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6743 - accuracy: 0.7128 - auc: 0.9184 - val_loss: 1.3267 - val_accuracy: 0.5277 - val_auc: 0.7968\n",
            "Epoch 109/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6761 - accuracy: 0.7082 - auc: 0.9179 - val_loss: 1.3321 - val_accuracy: 0.5253 - val_auc: 0.7941\n",
            "Epoch 110/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6717 - accuracy: 0.7108 - auc: 0.9189 - val_loss: 1.3217 - val_accuracy: 0.5238 - val_auc: 0.7924\n",
            "Epoch 111/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6703 - accuracy: 0.7140 - auc: 0.9193 - val_loss: 1.3093 - val_accuracy: 0.5217 - val_auc: 0.7950\n",
            "Epoch 112/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6697 - accuracy: 0.7121 - auc: 0.9194 - val_loss: 1.3545 - val_accuracy: 0.5172 - val_auc: 0.7892\n",
            "Epoch 113/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6713 - accuracy: 0.7095 - auc: 0.9191 - val_loss: 1.3196 - val_accuracy: 0.5256 - val_auc: 0.7945\n",
            "Epoch 114/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6674 - accuracy: 0.7129 - auc: 0.9200 - val_loss: 1.3403 - val_accuracy: 0.5268 - val_auc: 0.7910\n",
            "Epoch 115/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6690 - accuracy: 0.7105 - auc: 0.9193 - val_loss: 1.3557 - val_accuracy: 0.5346 - val_auc: 0.7945\n",
            "Epoch 116/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6653 - accuracy: 0.7137 - auc: 0.9204 - val_loss: 1.3567 - val_accuracy: 0.5283 - val_auc: 0.7924\n",
            "Epoch 117/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6649 - accuracy: 0.7155 - auc: 0.9208 - val_loss: 1.3561 - val_accuracy: 0.5175 - val_auc: 0.7923\n",
            "Epoch 118/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6663 - accuracy: 0.7157 - auc: 0.9201 - val_loss: 1.3642 - val_accuracy: 0.5262 - val_auc: 0.7937\n",
            "Epoch 119/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6661 - accuracy: 0.7152 - auc: 0.9202 - val_loss: 1.3517 - val_accuracy: 0.5229 - val_auc: 0.7918\n",
            "Epoch 120/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6657 - accuracy: 0.7147 - auc: 0.9204 - val_loss: 1.3531 - val_accuracy: 0.5325 - val_auc: 0.7935\n",
            "Epoch 121/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6620 - accuracy: 0.7154 - auc: 0.9212 - val_loss: 1.3704 - val_accuracy: 0.5199 - val_auc: 0.7880\n",
            "Epoch 122/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6618 - accuracy: 0.7163 - auc: 0.9213 - val_loss: 1.3662 - val_accuracy: 0.5187 - val_auc: 0.7900\n",
            "Epoch 123/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6594 - accuracy: 0.7186 - auc: 0.9218 - val_loss: 1.3672 - val_accuracy: 0.5298 - val_auc: 0.7949\n",
            "Epoch 124/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6596 - accuracy: 0.7168 - auc: 0.9217 - val_loss: 1.3676 - val_accuracy: 0.5292 - val_auc: 0.7940\n",
            "Epoch 125/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6614 - accuracy: 0.7186 - auc: 0.9213 - val_loss: 1.3823 - val_accuracy: 0.5241 - val_auc: 0.7935\n",
            "Epoch 126/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6598 - accuracy: 0.7174 - auc: 0.9216 - val_loss: 1.3616 - val_accuracy: 0.5265 - val_auc: 0.7954\n",
            "Epoch 127/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6607 - accuracy: 0.7162 - auc: 0.9214 - val_loss: 1.3765 - val_accuracy: 0.5184 - val_auc: 0.7909\n",
            "Epoch 128/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6566 - accuracy: 0.7161 - auc: 0.9224 - val_loss: 1.3943 - val_accuracy: 0.5301 - val_auc: 0.7966\n",
            "Epoch 129/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6564 - accuracy: 0.7172 - auc: 0.9224 - val_loss: 1.3804 - val_accuracy: 0.5226 - val_auc: 0.7911\n",
            "Epoch 130/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6552 - accuracy: 0.7167 - auc: 0.9228 - val_loss: 1.3829 - val_accuracy: 0.5292 - val_auc: 0.7957\n",
            "Epoch 131/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6560 - accuracy: 0.7167 - auc: 0.9225 - val_loss: 1.3928 - val_accuracy: 0.5223 - val_auc: 0.7909\n",
            "Epoch 132/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6564 - accuracy: 0.7213 - auc: 0.9225 - val_loss: 1.4110 - val_accuracy: 0.5058 - val_auc: 0.7842\n",
            "Epoch 133/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6558 - accuracy: 0.7214 - auc: 0.9225 - val_loss: 1.4200 - val_accuracy: 0.5157 - val_auc: 0.7867\n",
            "Epoch 134/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6559 - accuracy: 0.7222 - auc: 0.9227 - val_loss: 1.3944 - val_accuracy: 0.5181 - val_auc: 0.7868\n",
            "Epoch 135/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6518 - accuracy: 0.7224 - auc: 0.9234 - val_loss: 1.4092 - val_accuracy: 0.5220 - val_auc: 0.7898\n",
            "Epoch 136/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6533 - accuracy: 0.7216 - auc: 0.9233 - val_loss: 1.3998 - val_accuracy: 0.5217 - val_auc: 0.7911\n",
            "Epoch 137/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6531 - accuracy: 0.7182 - auc: 0.9234 - val_loss: 1.3932 - val_accuracy: 0.5304 - val_auc: 0.7917\n",
            "Epoch 138/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6523 - accuracy: 0.7224 - auc: 0.9236 - val_loss: 1.4227 - val_accuracy: 0.5169 - val_auc: 0.7911\n",
            "Epoch 139/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6522 - accuracy: 0.7156 - auc: 0.9234 - val_loss: 1.3997 - val_accuracy: 0.5253 - val_auc: 0.7929\n",
            "Epoch 140/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6500 - accuracy: 0.7176 - auc: 0.9240 - val_loss: 1.4135 - val_accuracy: 0.5256 - val_auc: 0.7958\n",
            "Epoch 141/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6489 - accuracy: 0.7220 - auc: 0.9242 - val_loss: 1.4266 - val_accuracy: 0.5298 - val_auc: 0.7930\n",
            "Epoch 142/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6503 - accuracy: 0.7220 - auc: 0.9238 - val_loss: 1.4166 - val_accuracy: 0.5313 - val_auc: 0.7932\n",
            "Epoch 143/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6469 - accuracy: 0.7220 - auc: 0.9247 - val_loss: 1.4233 - val_accuracy: 0.5196 - val_auc: 0.7879\n",
            "Epoch 144/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6511 - accuracy: 0.7220 - auc: 0.9236 - val_loss: 1.4239 - val_accuracy: 0.5205 - val_auc: 0.7860\n",
            "Epoch 145/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6476 - accuracy: 0.7245 - auc: 0.9247 - val_loss: 1.4508 - val_accuracy: 0.5181 - val_auc: 0.7871\n",
            "Epoch 146/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6489 - accuracy: 0.7214 - auc: 0.9241 - val_loss: 1.4232 - val_accuracy: 0.5247 - val_auc: 0.7879\n",
            "Epoch 147/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6473 - accuracy: 0.7237 - auc: 0.9246 - val_loss: 1.4557 - val_accuracy: 0.5295 - val_auc: 0.7926\n",
            "Epoch 148/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6454 - accuracy: 0.7234 - auc: 0.9249 - val_loss: 1.4406 - val_accuracy: 0.5223 - val_auc: 0.7864\n",
            "Epoch 149/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6466 - accuracy: 0.7224 - auc: 0.9247 - val_loss: 1.4295 - val_accuracy: 0.5133 - val_auc: 0.7882\n",
            "Epoch 150/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6455 - accuracy: 0.7219 - auc: 0.9248 - val_loss: 1.4401 - val_accuracy: 0.5208 - val_auc: 0.7878\n",
            "Epoch 151/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6437 - accuracy: 0.7264 - auc: 0.9255 - val_loss: 1.4383 - val_accuracy: 0.5229 - val_auc: 0.7911\n",
            "Epoch 152/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6449 - accuracy: 0.7218 - auc: 0.9253 - val_loss: 1.4457 - val_accuracy: 0.5172 - val_auc: 0.7873\n",
            "Epoch 153/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6438 - accuracy: 0.7261 - auc: 0.9254 - val_loss: 1.4464 - val_accuracy: 0.5262 - val_auc: 0.7930\n",
            "Epoch 154/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6442 - accuracy: 0.7219 - auc: 0.9254 - val_loss: 1.4575 - val_accuracy: 0.5235 - val_auc: 0.7887\n",
            "Epoch 155/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6402 - accuracy: 0.7249 - auc: 0.9261 - val_loss: 1.4627 - val_accuracy: 0.5250 - val_auc: 0.7903\n",
            "Epoch 156/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6403 - accuracy: 0.7275 - auc: 0.9262 - val_loss: 1.4562 - val_accuracy: 0.5250 - val_auc: 0.7915\n",
            "Epoch 157/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6424 - accuracy: 0.7271 - auc: 0.9257 - val_loss: 1.4821 - val_accuracy: 0.5268 - val_auc: 0.7872\n",
            "Epoch 158/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6409 - accuracy: 0.7267 - auc: 0.9263 - val_loss: 1.4525 - val_accuracy: 0.5259 - val_auc: 0.7897\n",
            "Epoch 159/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6391 - accuracy: 0.7266 - auc: 0.9263 - val_loss: 1.4762 - val_accuracy: 0.5127 - val_auc: 0.7870\n",
            "Epoch 160/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6401 - accuracy: 0.7257 - auc: 0.9263 - val_loss: 1.4652 - val_accuracy: 0.5214 - val_auc: 0.7904\n",
            "Epoch 161/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6378 - accuracy: 0.7290 - auc: 0.9267 - val_loss: 1.4666 - val_accuracy: 0.5277 - val_auc: 0.7927\n",
            "Epoch 162/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6368 - accuracy: 0.7308 - auc: 0.9268 - val_loss: 1.4673 - val_accuracy: 0.5199 - val_auc: 0.7872\n",
            "Epoch 163/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6390 - accuracy: 0.7233 - auc: 0.9263 - val_loss: 1.4635 - val_accuracy: 0.5142 - val_auc: 0.7863\n",
            "Epoch 164/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6373 - accuracy: 0.7257 - auc: 0.9269 - val_loss: 1.4775 - val_accuracy: 0.5178 - val_auc: 0.7858\n",
            "Epoch 165/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6365 - accuracy: 0.7290 - auc: 0.9268 - val_loss: 1.4822 - val_accuracy: 0.5250 - val_auc: 0.7898\n",
            "Epoch 166/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6348 - accuracy: 0.7287 - auc: 0.9273 - val_loss: 1.4833 - val_accuracy: 0.5112 - val_auc: 0.7857\n",
            "Epoch 167/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6340 - accuracy: 0.7322 - auc: 0.9276 - val_loss: 1.4703 - val_accuracy: 0.5253 - val_auc: 0.7926\n",
            "Epoch 168/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6331 - accuracy: 0.7294 - auc: 0.9278 - val_loss: 1.5113 - val_accuracy: 0.5163 - val_auc: 0.7848\n",
            "Epoch 169/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6351 - accuracy: 0.7270 - auc: 0.9272 - val_loss: 1.4916 - val_accuracy: 0.5223 - val_auc: 0.7878\n",
            "Epoch 170/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6351 - accuracy: 0.7270 - auc: 0.9274 - val_loss: 1.5091 - val_accuracy: 0.5091 - val_auc: 0.7811\n",
            "Epoch 171/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6311 - accuracy: 0.7319 - auc: 0.9282 - val_loss: 1.4957 - val_accuracy: 0.5232 - val_auc: 0.7878\n",
            "Epoch 172/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6318 - accuracy: 0.7293 - auc: 0.9281 - val_loss: 1.4889 - val_accuracy: 0.5238 - val_auc: 0.7866\n",
            "Epoch 173/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6322 - accuracy: 0.7281 - auc: 0.9278 - val_loss: 1.5050 - val_accuracy: 0.5217 - val_auc: 0.7898\n",
            "Epoch 174/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6317 - accuracy: 0.7294 - auc: 0.9280 - val_loss: 1.4897 - val_accuracy: 0.5253 - val_auc: 0.7885\n",
            "Epoch 175/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6280 - accuracy: 0.7300 - auc: 0.9289 - val_loss: 1.4993 - val_accuracy: 0.5157 - val_auc: 0.7826\n",
            "Epoch 176/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6278 - accuracy: 0.7337 - auc: 0.9288 - val_loss: 1.4865 - val_accuracy: 0.5163 - val_auc: 0.7846\n",
            "Epoch 177/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6301 - accuracy: 0.7329 - auc: 0.9285 - val_loss: 1.5178 - val_accuracy: 0.5202 - val_auc: 0.7881\n",
            "Epoch 178/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6271 - accuracy: 0.7326 - auc: 0.9291 - val_loss: 1.5147 - val_accuracy: 0.5154 - val_auc: 0.7881\n",
            "Epoch 179/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6317 - accuracy: 0.7297 - auc: 0.9279 - val_loss: 1.4977 - val_accuracy: 0.5121 - val_auc: 0.7838\n",
            "Epoch 180/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6274 - accuracy: 0.7296 - auc: 0.9290 - val_loss: 1.5343 - val_accuracy: 0.5088 - val_auc: 0.7810\n",
            "Epoch 181/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6284 - accuracy: 0.7319 - auc: 0.9288 - val_loss: 1.5439 - val_accuracy: 0.5082 - val_auc: 0.7786\n",
            "Epoch 182/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6269 - accuracy: 0.7322 - auc: 0.9290 - val_loss: 1.5270 - val_accuracy: 0.5124 - val_auc: 0.7842\n",
            "Epoch 183/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6285 - accuracy: 0.7338 - auc: 0.9289 - val_loss: 1.5275 - val_accuracy: 0.5175 - val_auc: 0.7855\n",
            "Epoch 184/500\n",
            "1003/1003 [==============================] - 4s 3ms/step - loss: 0.6271 - accuracy: 0.7325 - auc: 0.9290 - val_loss: 1.5309 - val_accuracy: 0.5262 - val_auc: 0.7883\n",
            "Epoch 185/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6258 - accuracy: 0.7320 - auc: 0.9291 - val_loss: 1.5326 - val_accuracy: 0.5214 - val_auc: 0.7897\n",
            "Epoch 186/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6275 - accuracy: 0.7330 - auc: 0.9288 - val_loss: 1.5401 - val_accuracy: 0.5151 - val_auc: 0.7838\n",
            "Epoch 187/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6244 - accuracy: 0.7350 - auc: 0.9298 - val_loss: 1.5218 - val_accuracy: 0.5181 - val_auc: 0.7852\n",
            "Epoch 188/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6214 - accuracy: 0.7318 - auc: 0.9304 - val_loss: 1.5349 - val_accuracy: 0.5277 - val_auc: 0.7923\n",
            "Epoch 189/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6224 - accuracy: 0.7377 - auc: 0.9304 - val_loss: 1.5240 - val_accuracy: 0.5280 - val_auc: 0.7889\n",
            "Epoch 190/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6244 - accuracy: 0.7370 - auc: 0.9298 - val_loss: 1.5414 - val_accuracy: 0.5064 - val_auc: 0.7804\n",
            "Epoch 191/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6241 - accuracy: 0.7306 - auc: 0.9298 - val_loss: 1.5440 - val_accuracy: 0.5247 - val_auc: 0.7880\n",
            "Epoch 192/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6233 - accuracy: 0.7350 - auc: 0.9301 - val_loss: 1.5449 - val_accuracy: 0.5109 - val_auc: 0.7802\n",
            "Epoch 193/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6235 - accuracy: 0.7361 - auc: 0.9299 - val_loss: 1.5526 - val_accuracy: 0.5256 - val_auc: 0.7859\n",
            "Epoch 194/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6210 - accuracy: 0.7389 - auc: 0.9306 - val_loss: 1.5514 - val_accuracy: 0.5250 - val_auc: 0.7914\n",
            "Epoch 195/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6227 - accuracy: 0.7376 - auc: 0.9300 - val_loss: 1.5523 - val_accuracy: 0.5238 - val_auc: 0.7865\n",
            "Epoch 196/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6199 - accuracy: 0.7358 - auc: 0.9306 - val_loss: 1.5549 - val_accuracy: 0.5181 - val_auc: 0.7868\n",
            "Epoch 197/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6218 - accuracy: 0.7350 - auc: 0.9304 - val_loss: 1.5508 - val_accuracy: 0.5190 - val_auc: 0.7864\n",
            "Epoch 198/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.6182 - accuracy: 0.7381 - auc: 0.9312 - val_loss: 1.5679 - val_accuracy: 0.5259 - val_auc: 0.7855\n",
            "Epoch 199/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6183 - accuracy: 0.7390 - auc: 0.9312 - val_loss: 1.5619 - val_accuracy: 0.5172 - val_auc: 0.7855\n",
            "Epoch 200/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6195 - accuracy: 0.7354 - auc: 0.9305 - val_loss: 1.5490 - val_accuracy: 0.5124 - val_auc: 0.7807\n",
            "Epoch 201/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6194 - accuracy: 0.7376 - auc: 0.9308 - val_loss: 1.5518 - val_accuracy: 0.5166 - val_auc: 0.7838\n",
            "Epoch 202/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6190 - accuracy: 0.7362 - auc: 0.9308 - val_loss: 1.5656 - val_accuracy: 0.5202 - val_auc: 0.7864\n",
            "Epoch 203/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6182 - accuracy: 0.7383 - auc: 0.9309 - val_loss: 1.5645 - val_accuracy: 0.5184 - val_auc: 0.7846\n",
            "Epoch 204/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6190 - accuracy: 0.7381 - auc: 0.9309 - val_loss: 1.5843 - val_accuracy: 0.5073 - val_auc: 0.7789\n",
            "Epoch 205/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6176 - accuracy: 0.7369 - auc: 0.9310 - val_loss: 1.5974 - val_accuracy: 0.5130 - val_auc: 0.7804\n",
            "Epoch 206/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6209 - accuracy: 0.7332 - auc: 0.9301 - val_loss: 1.5748 - val_accuracy: 0.5118 - val_auc: 0.7809\n",
            "Epoch 207/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6160 - accuracy: 0.7405 - auc: 0.9315 - val_loss: 1.5695 - val_accuracy: 0.5160 - val_auc: 0.7819\n",
            "Epoch 208/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6154 - accuracy: 0.7397 - auc: 0.9315 - val_loss: 1.5839 - val_accuracy: 0.5184 - val_auc: 0.7788\n",
            "Epoch 209/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6165 - accuracy: 0.7386 - auc: 0.9313 - val_loss: 1.5852 - val_accuracy: 0.5181 - val_auc: 0.7825\n",
            "Epoch 210/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6163 - accuracy: 0.7356 - auc: 0.9317 - val_loss: 1.5858 - val_accuracy: 0.5196 - val_auc: 0.7843\n",
            "Epoch 211/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6135 - accuracy: 0.7402 - auc: 0.9322 - val_loss: 1.5884 - val_accuracy: 0.5208 - val_auc: 0.7838\n",
            "Epoch 212/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6125 - accuracy: 0.7398 - auc: 0.9324 - val_loss: 1.5842 - val_accuracy: 0.5103 - val_auc: 0.7783\n",
            "Epoch 213/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6150 - accuracy: 0.7378 - auc: 0.9318 - val_loss: 1.5828 - val_accuracy: 0.5133 - val_auc: 0.7771\n",
            "Epoch 214/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6145 - accuracy: 0.7400 - auc: 0.9319 - val_loss: 1.6110 - val_accuracy: 0.5256 - val_auc: 0.7893\n",
            "Epoch 215/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6150 - accuracy: 0.7409 - auc: 0.9318 - val_loss: 1.6055 - val_accuracy: 0.5061 - val_auc: 0.7743\n",
            "Epoch 216/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6109 - accuracy: 0.7392 - auc: 0.9324 - val_loss: 1.5952 - val_accuracy: 0.5199 - val_auc: 0.7828\n",
            "Epoch 217/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6126 - accuracy: 0.7423 - auc: 0.9322 - val_loss: 1.5909 - val_accuracy: 0.5181 - val_auc: 0.7821\n",
            "Epoch 218/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6099 - accuracy: 0.7400 - auc: 0.9327 - val_loss: 1.6084 - val_accuracy: 0.5247 - val_auc: 0.7851\n",
            "Epoch 219/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6133 - accuracy: 0.7380 - auc: 0.9321 - val_loss: 1.6204 - val_accuracy: 0.5220 - val_auc: 0.7834\n",
            "Epoch 220/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6137 - accuracy: 0.7384 - auc: 0.9321 - val_loss: 1.6075 - val_accuracy: 0.5214 - val_auc: 0.7858\n",
            "Epoch 221/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6099 - accuracy: 0.7394 - auc: 0.9327 - val_loss: 1.6163 - val_accuracy: 0.5139 - val_auc: 0.7819\n",
            "Epoch 222/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.6119 - accuracy: 0.7396 - auc: 0.9325 - val_loss: 1.5946 - val_accuracy: 0.5160 - val_auc: 0.7801\n",
            "Epoch 223/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6118 - accuracy: 0.7391 - auc: 0.9322 - val_loss: 1.6291 - val_accuracy: 0.5154 - val_auc: 0.7832\n",
            "Epoch 224/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6135 - accuracy: 0.7415 - auc: 0.9322 - val_loss: 1.6113 - val_accuracy: 0.5112 - val_auc: 0.7770\n",
            "Epoch 225/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6103 - accuracy: 0.7375 - auc: 0.9329 - val_loss: 1.5985 - val_accuracy: 0.5112 - val_auc: 0.7798\n",
            "Epoch 226/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6078 - accuracy: 0.7418 - auc: 0.9333 - val_loss: 1.6293 - val_accuracy: 0.5115 - val_auc: 0.7805\n",
            "Epoch 227/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6101 - accuracy: 0.7425 - auc: 0.9327 - val_loss: 1.6243 - val_accuracy: 0.5046 - val_auc: 0.7766\n",
            "Epoch 228/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6095 - accuracy: 0.7389 - auc: 0.9327 - val_loss: 1.6162 - val_accuracy: 0.5118 - val_auc: 0.7818\n",
            "Epoch 229/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6110 - accuracy: 0.7379 - auc: 0.9327 - val_loss: 1.6173 - val_accuracy: 0.5160 - val_auc: 0.7800\n",
            "Epoch 230/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6082 - accuracy: 0.7441 - auc: 0.9331 - val_loss: 1.6182 - val_accuracy: 0.5142 - val_auc: 0.7828\n",
            "Epoch 231/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6050 - accuracy: 0.7431 - auc: 0.9340 - val_loss: 1.6164 - val_accuracy: 0.5244 - val_auc: 0.7856\n",
            "Epoch 232/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6106 - accuracy: 0.7397 - auc: 0.9328 - val_loss: 1.6256 - val_accuracy: 0.5064 - val_auc: 0.7769\n",
            "Epoch 233/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6061 - accuracy: 0.7403 - auc: 0.9332 - val_loss: 1.6261 - val_accuracy: 0.5151 - val_auc: 0.7807\n",
            "Epoch 234/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6036 - accuracy: 0.7451 - auc: 0.9342 - val_loss: 1.6319 - val_accuracy: 0.5208 - val_auc: 0.7870\n",
            "Epoch 235/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6097 - accuracy: 0.7393 - auc: 0.9328 - val_loss: 1.6304 - val_accuracy: 0.5091 - val_auc: 0.7777\n",
            "Epoch 236/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6046 - accuracy: 0.7447 - auc: 0.9340 - val_loss: 1.6123 - val_accuracy: 0.5175 - val_auc: 0.7813\n",
            "Epoch 237/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6033 - accuracy: 0.7501 - auc: 0.9343 - val_loss: 1.6557 - val_accuracy: 0.5217 - val_auc: 0.7844\n",
            "Epoch 238/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6039 - accuracy: 0.7418 - auc: 0.9343 - val_loss: 1.6453 - val_accuracy: 0.5058 - val_auc: 0.7758\n",
            "Epoch 239/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6049 - accuracy: 0.7441 - auc: 0.9339 - val_loss: 1.6428 - val_accuracy: 0.5190 - val_auc: 0.7838\n",
            "Epoch 240/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6071 - accuracy: 0.7416 - auc: 0.9333 - val_loss: 1.6611 - val_accuracy: 0.5121 - val_auc: 0.7806\n",
            "Epoch 241/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.6009 - accuracy: 0.7455 - auc: 0.9348 - val_loss: 1.6560 - val_accuracy: 0.5070 - val_auc: 0.7792\n",
            "Epoch 242/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6006 - accuracy: 0.7467 - auc: 0.9348 - val_loss: 1.6668 - val_accuracy: 0.5055 - val_auc: 0.7761\n",
            "Epoch 243/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6048 - accuracy: 0.7477 - auc: 0.9341 - val_loss: 1.6514 - val_accuracy: 0.5058 - val_auc: 0.7790\n",
            "Epoch 244/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6019 - accuracy: 0.7479 - auc: 0.9347 - val_loss: 1.6488 - val_accuracy: 0.5112 - val_auc: 0.7789\n",
            "Epoch 245/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6039 - accuracy: 0.7448 - auc: 0.9340 - val_loss: 1.6308 - val_accuracy: 0.5091 - val_auc: 0.7795\n",
            "Epoch 246/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6021 - accuracy: 0.7439 - auc: 0.9346 - val_loss: 1.6762 - val_accuracy: 0.5127 - val_auc: 0.7771\n",
            "Epoch 247/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6022 - accuracy: 0.7429 - auc: 0.9342 - val_loss: 1.6605 - val_accuracy: 0.5160 - val_auc: 0.7757\n",
            "Epoch 248/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5996 - accuracy: 0.7455 - auc: 0.9349 - val_loss: 1.6705 - val_accuracy: 0.5226 - val_auc: 0.7825\n",
            "Epoch 249/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.6030 - accuracy: 0.7435 - auc: 0.9342 - val_loss: 1.6518 - val_accuracy: 0.5253 - val_auc: 0.7823\n",
            "Epoch 250/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6022 - accuracy: 0.7408 - auc: 0.9347 - val_loss: 1.6734 - val_accuracy: 0.5127 - val_auc: 0.7750\n",
            "Epoch 251/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6003 - accuracy: 0.7450 - auc: 0.9348 - val_loss: 1.6627 - val_accuracy: 0.5094 - val_auc: 0.7798\n",
            "Epoch 252/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5983 - accuracy: 0.7450 - auc: 0.9353 - val_loss: 1.6630 - val_accuracy: 0.5193 - val_auc: 0.7840\n",
            "Epoch 253/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.6020 - accuracy: 0.7447 - auc: 0.9344 - val_loss: 1.6653 - val_accuracy: 0.5220 - val_auc: 0.7797\n",
            "Epoch 254/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5974 - accuracy: 0.7463 - auc: 0.9353 - val_loss: 1.6726 - val_accuracy: 0.5199 - val_auc: 0.7800\n",
            "Epoch 255/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5975 - accuracy: 0.7483 - auc: 0.9355 - val_loss: 1.6890 - val_accuracy: 0.4972 - val_auc: 0.7680\n",
            "Epoch 256/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.5994 - accuracy: 0.7418 - auc: 0.9349 - val_loss: 1.6736 - val_accuracy: 0.5208 - val_auc: 0.7811\n",
            "Epoch 257/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5952 - accuracy: 0.7486 - auc: 0.9359 - val_loss: 1.7034 - val_accuracy: 0.5085 - val_auc: 0.7793\n",
            "Epoch 258/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5983 - accuracy: 0.7478 - auc: 0.9353 - val_loss: 1.6984 - val_accuracy: 0.5076 - val_auc: 0.7742\n",
            "Epoch 259/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5984 - accuracy: 0.7445 - auc: 0.9352 - val_loss: 1.6989 - val_accuracy: 0.5106 - val_auc: 0.7757\n",
            "Epoch 260/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5987 - accuracy: 0.7450 - auc: 0.9350 - val_loss: 1.6835 - val_accuracy: 0.5232 - val_auc: 0.7836\n",
            "Epoch 261/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5976 - accuracy: 0.7470 - auc: 0.9354 - val_loss: 1.6918 - val_accuracy: 0.5205 - val_auc: 0.7813\n",
            "Epoch 262/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5938 - accuracy: 0.7473 - auc: 0.9364 - val_loss: 1.7033 - val_accuracy: 0.5196 - val_auc: 0.7819\n",
            "Epoch 263/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5985 - accuracy: 0.7432 - auc: 0.9351 - val_loss: 1.6692 - val_accuracy: 0.5148 - val_auc: 0.7763\n",
            "Epoch 264/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5956 - accuracy: 0.7486 - auc: 0.9359 - val_loss: 1.6965 - val_accuracy: 0.5124 - val_auc: 0.7781\n",
            "Epoch 265/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5933 - accuracy: 0.7499 - auc: 0.9363 - val_loss: 1.7031 - val_accuracy: 0.5154 - val_auc: 0.7769\n",
            "Epoch 266/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5968 - accuracy: 0.7424 - auc: 0.9355 - val_loss: 1.6974 - val_accuracy: 0.5196 - val_auc: 0.7789\n",
            "Epoch 267/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5917 - accuracy: 0.7442 - auc: 0.9365 - val_loss: 1.7048 - val_accuracy: 0.5163 - val_auc: 0.7766\n",
            "Epoch 268/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5938 - accuracy: 0.7447 - auc: 0.9362 - val_loss: 1.7129 - val_accuracy: 0.5091 - val_auc: 0.7761\n",
            "Epoch 269/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5946 - accuracy: 0.7469 - auc: 0.9360 - val_loss: 1.7225 - val_accuracy: 0.5082 - val_auc: 0.7798\n",
            "Epoch 270/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5940 - accuracy: 0.7448 - auc: 0.9361 - val_loss: 1.6928 - val_accuracy: 0.5145 - val_auc: 0.7789\n",
            "Epoch 271/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5917 - accuracy: 0.7518 - auc: 0.9368 - val_loss: 1.7322 - val_accuracy: 0.5139 - val_auc: 0.7773\n",
            "Epoch 272/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5916 - accuracy: 0.7504 - auc: 0.9368 - val_loss: 1.7236 - val_accuracy: 0.5172 - val_auc: 0.7778\n",
            "Epoch 273/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5972 - accuracy: 0.7457 - auc: 0.9354 - val_loss: 1.7211 - val_accuracy: 0.5148 - val_auc: 0.7744\n",
            "Epoch 274/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5906 - accuracy: 0.7488 - auc: 0.9369 - val_loss: 1.7398 - val_accuracy: 0.5142 - val_auc: 0.7793\n",
            "Epoch 275/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5920 - accuracy: 0.7493 - auc: 0.9367 - val_loss: 1.7171 - val_accuracy: 0.5034 - val_auc: 0.7732\n",
            "Epoch 276/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5931 - accuracy: 0.7490 - auc: 0.9363 - val_loss: 1.7054 - val_accuracy: 0.5163 - val_auc: 0.7774\n",
            "Epoch 277/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5915 - accuracy: 0.7477 - auc: 0.9366 - val_loss: 1.7355 - val_accuracy: 0.5190 - val_auc: 0.7813\n",
            "Epoch 278/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5917 - accuracy: 0.7493 - auc: 0.9366 - val_loss: 1.7271 - val_accuracy: 0.5040 - val_auc: 0.7751\n",
            "Epoch 279/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5890 - accuracy: 0.7491 - auc: 0.9371 - val_loss: 1.7253 - val_accuracy: 0.5265 - val_auc: 0.7846\n",
            "Epoch 280/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5890 - accuracy: 0.7496 - auc: 0.9373 - val_loss: 1.7131 - val_accuracy: 0.5184 - val_auc: 0.7806\n",
            "Epoch 281/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5919 - accuracy: 0.7480 - auc: 0.9367 - val_loss: 1.7661 - val_accuracy: 0.4966 - val_auc: 0.7656\n",
            "Epoch 282/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5955 - accuracy: 0.7425 - auc: 0.9355 - val_loss: 1.7018 - val_accuracy: 0.5094 - val_auc: 0.7765\n",
            "Epoch 283/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5918 - accuracy: 0.7491 - auc: 0.9368 - val_loss: 1.7290 - val_accuracy: 0.5142 - val_auc: 0.7786\n",
            "Epoch 284/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5892 - accuracy: 0.7516 - auc: 0.9371 - val_loss: 1.7270 - val_accuracy: 0.5055 - val_auc: 0.7760\n",
            "Epoch 285/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5890 - accuracy: 0.7539 - auc: 0.9372 - val_loss: 1.7594 - val_accuracy: 0.5094 - val_auc: 0.7696\n",
            "Epoch 286/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5896 - accuracy: 0.7467 - auc: 0.9369 - val_loss: 1.7633 - val_accuracy: 0.5208 - val_auc: 0.7836\n",
            "Epoch 287/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5884 - accuracy: 0.7508 - auc: 0.9374 - val_loss: 1.7427 - val_accuracy: 0.5217 - val_auc: 0.7770\n",
            "Epoch 288/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5871 - accuracy: 0.7497 - auc: 0.9376 - val_loss: 1.7594 - val_accuracy: 0.5130 - val_auc: 0.7791\n",
            "Epoch 289/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5913 - accuracy: 0.7503 - auc: 0.9368 - val_loss: 1.7462 - val_accuracy: 0.5190 - val_auc: 0.7825\n",
            "Epoch 290/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5872 - accuracy: 0.7533 - auc: 0.9375 - val_loss: 1.7554 - val_accuracy: 0.5058 - val_auc: 0.7738\n",
            "Epoch 291/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5905 - accuracy: 0.7483 - auc: 0.9368 - val_loss: 1.7799 - val_accuracy: 0.5076 - val_auc: 0.7789\n",
            "Epoch 292/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5876 - accuracy: 0.7505 - auc: 0.9374 - val_loss: 1.7476 - val_accuracy: 0.5154 - val_auc: 0.7795\n",
            "Epoch 293/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5854 - accuracy: 0.7506 - auc: 0.9380 - val_loss: 1.7657 - val_accuracy: 0.5031 - val_auc: 0.7711\n",
            "Epoch 294/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5872 - accuracy: 0.7526 - auc: 0.9376 - val_loss: 1.7816 - val_accuracy: 0.5163 - val_auc: 0.7760\n",
            "Epoch 295/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.5852 - accuracy: 0.7522 - auc: 0.9377 - val_loss: 1.7870 - val_accuracy: 0.5088 - val_auc: 0.7731\n",
            "Epoch 296/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5866 - accuracy: 0.7521 - auc: 0.9376 - val_loss: 1.7430 - val_accuracy: 0.5055 - val_auc: 0.7731\n",
            "Epoch 297/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5862 - accuracy: 0.7528 - auc: 0.9378 - val_loss: 1.7492 - val_accuracy: 0.5076 - val_auc: 0.7801\n",
            "Epoch 298/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5844 - accuracy: 0.7489 - auc: 0.9380 - val_loss: 1.7799 - val_accuracy: 0.5034 - val_auc: 0.7725\n",
            "Epoch 299/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5841 - accuracy: 0.7505 - auc: 0.9382 - val_loss: 1.7685 - val_accuracy: 0.5097 - val_auc: 0.7763\n",
            "Epoch 300/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5852 - accuracy: 0.7480 - auc: 0.9379 - val_loss: 1.7887 - val_accuracy: 0.5199 - val_auc: 0.7799\n",
            "Epoch 301/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5828 - accuracy: 0.7526 - auc: 0.9384 - val_loss: 1.7866 - val_accuracy: 0.5052 - val_auc: 0.7728\n",
            "Epoch 302/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5830 - accuracy: 0.7539 - auc: 0.9387 - val_loss: 1.7710 - val_accuracy: 0.5058 - val_auc: 0.7735\n",
            "Epoch 303/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5830 - accuracy: 0.7496 - auc: 0.9386 - val_loss: 1.7699 - val_accuracy: 0.5187 - val_auc: 0.7795\n",
            "Epoch 304/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5846 - accuracy: 0.7496 - auc: 0.9383 - val_loss: 1.8114 - val_accuracy: 0.5094 - val_auc: 0.7734\n",
            "Epoch 305/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5853 - accuracy: 0.7522 - auc: 0.9379 - val_loss: 1.7729 - val_accuracy: 0.5100 - val_auc: 0.7776\n",
            "Epoch 306/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5816 - accuracy: 0.7519 - auc: 0.9388 - val_loss: 1.7876 - val_accuracy: 0.5121 - val_auc: 0.7734\n",
            "Epoch 307/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5836 - accuracy: 0.7524 - auc: 0.9383 - val_loss: 1.7924 - val_accuracy: 0.5085 - val_auc: 0.7706\n",
            "Epoch 308/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5820 - accuracy: 0.7505 - auc: 0.9387 - val_loss: 1.8040 - val_accuracy: 0.5040 - val_auc: 0.7721\n",
            "Epoch 309/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5828 - accuracy: 0.7522 - auc: 0.9383 - val_loss: 1.8070 - val_accuracy: 0.5073 - val_auc: 0.7731\n",
            "Epoch 310/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5820 - accuracy: 0.7513 - auc: 0.9389 - val_loss: 1.7860 - val_accuracy: 0.5082 - val_auc: 0.7742\n",
            "Epoch 311/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5814 - accuracy: 0.7523 - auc: 0.9387 - val_loss: 1.7973 - val_accuracy: 0.5127 - val_auc: 0.7747\n",
            "Epoch 312/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5843 - accuracy: 0.7535 - auc: 0.9381 - val_loss: 1.7972 - val_accuracy: 0.5115 - val_auc: 0.7771\n",
            "Epoch 313/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5802 - accuracy: 0.7511 - auc: 0.9389 - val_loss: 1.8264 - val_accuracy: 0.5112 - val_auc: 0.7763\n",
            "Epoch 314/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.5799 - accuracy: 0.7551 - auc: 0.9391 - val_loss: 1.8105 - val_accuracy: 0.5169 - val_auc: 0.7791\n",
            "Epoch 315/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5812 - accuracy: 0.7540 - auc: 0.9389 - val_loss: 1.8166 - val_accuracy: 0.5001 - val_auc: 0.7731\n",
            "Epoch 316/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5838 - accuracy: 0.7494 - auc: 0.9384 - val_loss: 1.8024 - val_accuracy: 0.5121 - val_auc: 0.7770\n",
            "Epoch 317/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5802 - accuracy: 0.7531 - auc: 0.9391 - val_loss: 1.8256 - val_accuracy: 0.5043 - val_auc: 0.7751\n",
            "Epoch 318/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5832 - accuracy: 0.7495 - auc: 0.9383 - val_loss: 1.8249 - val_accuracy: 0.5115 - val_auc: 0.7730\n",
            "Epoch 319/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.5773 - accuracy: 0.7543 - auc: 0.9396 - val_loss: 1.8320 - val_accuracy: 0.5010 - val_auc: 0.7714\n",
            "Epoch 320/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5818 - accuracy: 0.7540 - auc: 0.9387 - val_loss: 1.8069 - val_accuracy: 0.5004 - val_auc: 0.7719\n",
            "Epoch 321/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5786 - accuracy: 0.7541 - auc: 0.9393 - val_loss: 1.8133 - val_accuracy: 0.5073 - val_auc: 0.7731\n",
            "Epoch 322/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5821 - accuracy: 0.7539 - auc: 0.9388 - val_loss: 1.8385 - val_accuracy: 0.5133 - val_auc: 0.7765\n",
            "Epoch 323/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5785 - accuracy: 0.7587 - auc: 0.9395 - val_loss: 1.8377 - val_accuracy: 0.5106 - val_auc: 0.7744\n",
            "Epoch 324/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5779 - accuracy: 0.7574 - auc: 0.9395 - val_loss: 1.8318 - val_accuracy: 0.5082 - val_auc: 0.7730\n",
            "Epoch 325/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5780 - accuracy: 0.7559 - auc: 0.9393 - val_loss: 1.8446 - val_accuracy: 0.5124 - val_auc: 0.7737\n",
            "Epoch 326/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5789 - accuracy: 0.7491 - auc: 0.9393 - val_loss: 1.8476 - val_accuracy: 0.5007 - val_auc: 0.7735\n",
            "Epoch 327/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5794 - accuracy: 0.7524 - auc: 0.9392 - val_loss: 1.8295 - val_accuracy: 0.5040 - val_auc: 0.7746\n",
            "Epoch 328/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5762 - accuracy: 0.7557 - auc: 0.9399 - val_loss: 1.8498 - val_accuracy: 0.4963 - val_auc: 0.7666\n",
            "Epoch 329/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.5777 - accuracy: 0.7529 - auc: 0.9394 - val_loss: 1.8620 - val_accuracy: 0.5085 - val_auc: 0.7772\n",
            "Epoch 330/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5792 - accuracy: 0.7545 - auc: 0.9393 - val_loss: 1.8218 - val_accuracy: 0.5082 - val_auc: 0.7735\n",
            "Epoch 331/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5755 - accuracy: 0.7521 - auc: 0.9396 - val_loss: 1.8497 - val_accuracy: 0.5085 - val_auc: 0.7728\n",
            "Epoch 332/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5778 - accuracy: 0.7518 - auc: 0.9393 - val_loss: 1.8485 - val_accuracy: 0.4978 - val_auc: 0.7680\n",
            "Epoch 333/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5784 - accuracy: 0.7560 - auc: 0.9393 - val_loss: 1.8314 - val_accuracy: 0.5037 - val_auc: 0.7756\n",
            "Epoch 334/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5764 - accuracy: 0.7562 - auc: 0.9397 - val_loss: 1.8685 - val_accuracy: 0.5070 - val_auc: 0.7758\n",
            "Epoch 335/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5762 - accuracy: 0.7526 - auc: 0.9396 - val_loss: 1.8652 - val_accuracy: 0.5022 - val_auc: 0.7699\n",
            "Epoch 336/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5741 - accuracy: 0.7569 - auc: 0.9401 - val_loss: 1.8522 - val_accuracy: 0.5136 - val_auc: 0.7760\n",
            "Epoch 337/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5748 - accuracy: 0.7536 - auc: 0.9400 - val_loss: 1.8507 - val_accuracy: 0.5115 - val_auc: 0.7773\n",
            "Epoch 338/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5785 - accuracy: 0.7558 - auc: 0.9394 - val_loss: 1.8772 - val_accuracy: 0.4993 - val_auc: 0.7732\n",
            "Epoch 339/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5758 - accuracy: 0.7553 - auc: 0.9400 - val_loss: 1.8490 - val_accuracy: 0.5052 - val_auc: 0.7729\n",
            "Epoch 340/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5753 - accuracy: 0.7550 - auc: 0.9400 - val_loss: 1.8708 - val_accuracy: 0.5133 - val_auc: 0.7771\n",
            "Epoch 341/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5763 - accuracy: 0.7553 - auc: 0.9396 - val_loss: 1.8348 - val_accuracy: 0.5034 - val_auc: 0.7727\n",
            "Epoch 342/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5747 - accuracy: 0.7534 - auc: 0.9400 - val_loss: 1.8599 - val_accuracy: 0.5052 - val_auc: 0.7728\n",
            "Epoch 343/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5735 - accuracy: 0.7533 - auc: 0.9405 - val_loss: 1.8561 - val_accuracy: 0.5094 - val_auc: 0.7764\n",
            "Epoch 344/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5729 - accuracy: 0.7545 - auc: 0.9404 - val_loss: 1.8638 - val_accuracy: 0.5019 - val_auc: 0.7712\n",
            "Epoch 345/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5756 - accuracy: 0.7556 - auc: 0.9398 - val_loss: 1.8547 - val_accuracy: 0.5091 - val_auc: 0.7719\n",
            "Epoch 346/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5711 - accuracy: 0.7613 - auc: 0.9407 - val_loss: 1.8722 - val_accuracy: 0.5088 - val_auc: 0.7777\n",
            "Epoch 347/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5776 - accuracy: 0.7501 - auc: 0.9393 - val_loss: 1.8673 - val_accuracy: 0.5106 - val_auc: 0.7739\n",
            "Epoch 348/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5718 - accuracy: 0.7604 - auc: 0.9408 - val_loss: 1.8802 - val_accuracy: 0.5037 - val_auc: 0.7686\n",
            "Epoch 349/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5727 - accuracy: 0.7567 - auc: 0.9403 - val_loss: 1.8619 - val_accuracy: 0.5031 - val_auc: 0.7711\n",
            "Epoch 350/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5716 - accuracy: 0.7558 - auc: 0.9406 - val_loss: 1.8958 - val_accuracy: 0.5061 - val_auc: 0.7711\n",
            "Epoch 351/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5734 - accuracy: 0.7578 - auc: 0.9403 - val_loss: 1.8961 - val_accuracy: 0.5043 - val_auc: 0.7665\n",
            "Epoch 352/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5732 - accuracy: 0.7556 - auc: 0.9405 - val_loss: 1.8671 - val_accuracy: 0.5034 - val_auc: 0.7723\n",
            "Epoch 353/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5735 - accuracy: 0.7546 - auc: 0.9401 - val_loss: 1.8825 - val_accuracy: 0.5064 - val_auc: 0.7711\n",
            "Epoch 354/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5691 - accuracy: 0.7627 - auc: 0.9413 - val_loss: 1.8738 - val_accuracy: 0.5085 - val_auc: 0.7768\n",
            "Epoch 355/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5746 - accuracy: 0.7569 - auc: 0.9400 - val_loss: 1.8812 - val_accuracy: 0.5112 - val_auc: 0.7726\n",
            "Epoch 356/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5711 - accuracy: 0.7602 - auc: 0.9408 - val_loss: 1.8797 - val_accuracy: 0.5064 - val_auc: 0.7740\n",
            "Epoch 357/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5724 - accuracy: 0.7561 - auc: 0.9405 - val_loss: 1.9056 - val_accuracy: 0.5016 - val_auc: 0.7719\n",
            "Epoch 358/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5715 - accuracy: 0.7556 - auc: 0.9405 - val_loss: 1.9158 - val_accuracy: 0.5073 - val_auc: 0.7734\n",
            "Epoch 359/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5674 - accuracy: 0.7603 - auc: 0.9416 - val_loss: 1.8874 - val_accuracy: 0.4987 - val_auc: 0.7658\n",
            "Epoch 360/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5697 - accuracy: 0.7572 - auc: 0.9412 - val_loss: 1.8947 - val_accuracy: 0.5088 - val_auc: 0.7735\n",
            "Epoch 361/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5706 - accuracy: 0.7557 - auc: 0.9409 - val_loss: 1.8729 - val_accuracy: 0.5067 - val_auc: 0.7735\n",
            "Epoch 362/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5684 - accuracy: 0.7539 - auc: 0.9413 - val_loss: 1.9435 - val_accuracy: 0.4978 - val_auc: 0.7638\n",
            "Epoch 363/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5723 - accuracy: 0.7551 - auc: 0.9405 - val_loss: 1.8725 - val_accuracy: 0.5058 - val_auc: 0.7678\n",
            "Epoch 364/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5685 - accuracy: 0.7578 - auc: 0.9413 - val_loss: 1.8832 - val_accuracy: 0.5115 - val_auc: 0.7764\n",
            "Epoch 365/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5677 - accuracy: 0.7578 - auc: 0.9413 - val_loss: 1.9026 - val_accuracy: 0.5115 - val_auc: 0.7743\n",
            "Epoch 366/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5700 - accuracy: 0.7568 - auc: 0.9409 - val_loss: 1.9024 - val_accuracy: 0.5112 - val_auc: 0.7742\n",
            "Epoch 367/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.5695 - accuracy: 0.7574 - auc: 0.9411 - val_loss: 1.9126 - val_accuracy: 0.4999 - val_auc: 0.7685\n",
            "Epoch 368/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5684 - accuracy: 0.7554 - auc: 0.9413 - val_loss: 1.9033 - val_accuracy: 0.5016 - val_auc: 0.7700\n",
            "Epoch 369/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5683 - accuracy: 0.7572 - auc: 0.9412 - val_loss: 1.9298 - val_accuracy: 0.5118 - val_auc: 0.7706\n",
            "Epoch 370/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5665 - accuracy: 0.7572 - auc: 0.9416 - val_loss: 1.9350 - val_accuracy: 0.5187 - val_auc: 0.7762\n",
            "Epoch 371/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5666 - accuracy: 0.7539 - auc: 0.9415 - val_loss: 1.9459 - val_accuracy: 0.5112 - val_auc: 0.7728\n",
            "Epoch 372/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5685 - accuracy: 0.7570 - auc: 0.9410 - val_loss: 1.9456 - val_accuracy: 0.5163 - val_auc: 0.7757\n",
            "Epoch 373/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5677 - accuracy: 0.7549 - auc: 0.9413 - val_loss: 1.9299 - val_accuracy: 0.5049 - val_auc: 0.7711\n",
            "Epoch 374/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5660 - accuracy: 0.7619 - auc: 0.9415 - val_loss: 1.9287 - val_accuracy: 0.4993 - val_auc: 0.7651\n",
            "Epoch 375/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5712 - accuracy: 0.7545 - auc: 0.9406 - val_loss: 1.9171 - val_accuracy: 0.5064 - val_auc: 0.7733\n",
            "Epoch 376/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5663 - accuracy: 0.7608 - auc: 0.9418 - val_loss: 1.9142 - val_accuracy: 0.5085 - val_auc: 0.7763\n",
            "Epoch 377/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5663 - accuracy: 0.7575 - auc: 0.9417 - val_loss: 1.9188 - val_accuracy: 0.5091 - val_auc: 0.7718\n",
            "Epoch 378/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5650 - accuracy: 0.7581 - auc: 0.9419 - val_loss: 1.9396 - val_accuracy: 0.5094 - val_auc: 0.7716\n",
            "Epoch 379/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5661 - accuracy: 0.7584 - auc: 0.9416 - val_loss: 1.9142 - val_accuracy: 0.4990 - val_auc: 0.7679\n",
            "Epoch 380/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.5695 - accuracy: 0.7565 - auc: 0.9410 - val_loss: 1.9280 - val_accuracy: 0.5019 - val_auc: 0.7656\n",
            "Epoch 381/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5653 - accuracy: 0.7574 - auc: 0.9418 - val_loss: 1.9312 - val_accuracy: 0.5193 - val_auc: 0.7769\n",
            "Epoch 382/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5702 - accuracy: 0.7583 - auc: 0.9409 - val_loss: 1.9455 - val_accuracy: 0.5085 - val_auc: 0.7720\n",
            "Epoch 383/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.5630 - accuracy: 0.7602 - auc: 0.9422 - val_loss: 1.9416 - val_accuracy: 0.5121 - val_auc: 0.7773\n",
            "Epoch 384/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.5651 - accuracy: 0.7609 - auc: 0.9420 - val_loss: 1.9590 - val_accuracy: 0.5064 - val_auc: 0.7728\n",
            "Epoch 385/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.5651 - accuracy: 0.7592 - auc: 0.9419 - val_loss: 1.9643 - val_accuracy: 0.5109 - val_auc: 0.7743\n",
            "Epoch 386/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5625 - accuracy: 0.7608 - auc: 0.9425 - val_loss: 1.9842 - val_accuracy: 0.5088 - val_auc: 0.7703\n",
            "Epoch 387/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5654 - accuracy: 0.7558 - auc: 0.9417 - val_loss: 1.9540 - val_accuracy: 0.5091 - val_auc: 0.7703\n",
            "Epoch 388/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5637 - accuracy: 0.7601 - auc: 0.9424 - val_loss: 1.9874 - val_accuracy: 0.5085 - val_auc: 0.7742\n",
            "Epoch 389/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5704 - accuracy: 0.7577 - auc: 0.9408 - val_loss: 1.9483 - val_accuracy: 0.5040 - val_auc: 0.7690\n",
            "Epoch 390/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5655 - accuracy: 0.7595 - auc: 0.9419 - val_loss: 1.9235 - val_accuracy: 0.5010 - val_auc: 0.7654\n",
            "Epoch 391/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5654 - accuracy: 0.7624 - auc: 0.9421 - val_loss: 1.9589 - val_accuracy: 0.5088 - val_auc: 0.7698\n",
            "Epoch 392/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5636 - accuracy: 0.7599 - auc: 0.9422 - val_loss: 1.9628 - val_accuracy: 0.5016 - val_auc: 0.7693\n",
            "Epoch 393/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5616 - accuracy: 0.7603 - auc: 0.9425 - val_loss: 1.9603 - val_accuracy: 0.5022 - val_auc: 0.7673\n",
            "Epoch 394/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.5659 - accuracy: 0.7584 - auc: 0.9417 - val_loss: 1.9457 - val_accuracy: 0.5088 - val_auc: 0.7712\n",
            "Epoch 395/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5633 - accuracy: 0.7593 - auc: 0.9424 - val_loss: 1.9866 - val_accuracy: 0.5022 - val_auc: 0.7701\n",
            "Epoch 396/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5607 - accuracy: 0.7598 - auc: 0.9428 - val_loss: 1.9619 - val_accuracy: 0.5136 - val_auc: 0.7720\n",
            "Epoch 397/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5635 - accuracy: 0.7589 - auc: 0.9422 - val_loss: 1.9586 - val_accuracy: 0.5112 - val_auc: 0.7710\n",
            "Epoch 398/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5631 - accuracy: 0.7609 - auc: 0.9423 - val_loss: 1.9975 - val_accuracy: 0.5079 - val_auc: 0.7720\n",
            "Epoch 399/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5610 - accuracy: 0.7567 - auc: 0.9425 - val_loss: 1.9903 - val_accuracy: 0.5112 - val_auc: 0.7720\n",
            "Epoch 400/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5656 - accuracy: 0.7583 - auc: 0.9416 - val_loss: 1.9648 - val_accuracy: 0.5055 - val_auc: 0.7697\n",
            "Epoch 401/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5611 - accuracy: 0.7635 - auc: 0.9429 - val_loss: 1.9750 - val_accuracy: 0.4972 - val_auc: 0.7677\n",
            "Epoch 402/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5605 - accuracy: 0.7596 - auc: 0.9426 - val_loss: 1.9760 - val_accuracy: 0.5160 - val_auc: 0.7725\n",
            "Epoch 403/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5652 - accuracy: 0.7578 - auc: 0.9417 - val_loss: 1.9849 - val_accuracy: 0.5034 - val_auc: 0.7668\n",
            "Epoch 404/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5609 - accuracy: 0.7610 - auc: 0.9429 - val_loss: 1.9949 - val_accuracy: 0.4996 - val_auc: 0.7631\n",
            "Epoch 405/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5629 - accuracy: 0.7631 - auc: 0.9425 - val_loss: 2.0242 - val_accuracy: 0.5103 - val_auc: 0.7721\n",
            "Epoch 406/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5659 - accuracy: 0.7590 - auc: 0.9417 - val_loss: 2.0031 - val_accuracy: 0.5016 - val_auc: 0.7670\n",
            "Epoch 407/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5619 - accuracy: 0.7610 - auc: 0.9425 - val_loss: 1.9829 - val_accuracy: 0.5070 - val_auc: 0.7696\n",
            "Epoch 408/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5623 - accuracy: 0.7568 - auc: 0.9423 - val_loss: 2.0099 - val_accuracy: 0.5133 - val_auc: 0.7709\n",
            "Epoch 409/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5609 - accuracy: 0.7580 - auc: 0.9427 - val_loss: 2.0032 - val_accuracy: 0.5061 - val_auc: 0.7662\n",
            "Epoch 410/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5594 - accuracy: 0.7622 - auc: 0.9428 - val_loss: 2.0151 - val_accuracy: 0.5037 - val_auc: 0.7688\n",
            "Epoch 411/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5608 - accuracy: 0.7569 - auc: 0.9426 - val_loss: 2.0171 - val_accuracy: 0.5157 - val_auc: 0.7717\n",
            "Epoch 412/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5604 - accuracy: 0.7600 - auc: 0.9430 - val_loss: 1.9980 - val_accuracy: 0.5130 - val_auc: 0.7693\n",
            "Epoch 413/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5609 - accuracy: 0.7594 - auc: 0.9425 - val_loss: 2.0056 - val_accuracy: 0.5034 - val_auc: 0.7668\n",
            "Epoch 414/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5591 - accuracy: 0.7609 - auc: 0.9430 - val_loss: 2.0132 - val_accuracy: 0.5094 - val_auc: 0.7712\n",
            "Epoch 415/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5635 - accuracy: 0.7566 - auc: 0.9421 - val_loss: 2.0032 - val_accuracy: 0.5007 - val_auc: 0.7654\n",
            "Epoch 416/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5600 - accuracy: 0.7586 - auc: 0.9426 - val_loss: 1.9920 - val_accuracy: 0.5070 - val_auc: 0.7719\n",
            "Epoch 417/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5613 - accuracy: 0.7616 - auc: 0.9427 - val_loss: 2.0322 - val_accuracy: 0.4954 - val_auc: 0.7655\n",
            "Epoch 418/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5606 - accuracy: 0.7594 - auc: 0.9427 - val_loss: 2.0133 - val_accuracy: 0.5067 - val_auc: 0.7688\n",
            "Epoch 419/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5594 - accuracy: 0.7609 - auc: 0.9430 - val_loss: 1.9907 - val_accuracy: 0.5010 - val_auc: 0.7639\n",
            "Epoch 420/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5608 - accuracy: 0.7618 - auc: 0.9428 - val_loss: 1.9931 - val_accuracy: 0.5070 - val_auc: 0.7709\n",
            "Epoch 421/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5617 - accuracy: 0.7588 - auc: 0.9426 - val_loss: 2.0102 - val_accuracy: 0.5061 - val_auc: 0.7696\n",
            "Epoch 422/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5610 - accuracy: 0.7613 - auc: 0.9426 - val_loss: 2.0093 - val_accuracy: 0.5067 - val_auc: 0.7697\n",
            "Epoch 423/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5561 - accuracy: 0.7602 - auc: 0.9435 - val_loss: 2.0348 - val_accuracy: 0.5085 - val_auc: 0.7720\n",
            "Epoch 424/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5563 - accuracy: 0.7631 - auc: 0.9435 - val_loss: 2.0629 - val_accuracy: 0.5106 - val_auc: 0.7678\n",
            "Epoch 425/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5630 - accuracy: 0.7614 - auc: 0.9423 - val_loss: 2.0127 - val_accuracy: 0.5145 - val_auc: 0.7705\n",
            "Epoch 426/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5575 - accuracy: 0.7584 - auc: 0.9432 - val_loss: 2.0194 - val_accuracy: 0.5091 - val_auc: 0.7711\n",
            "Epoch 427/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5627 - accuracy: 0.7551 - auc: 0.9422 - val_loss: 2.0423 - val_accuracy: 0.4987 - val_auc: 0.7677\n",
            "Epoch 428/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5599 - accuracy: 0.7618 - auc: 0.9427 - val_loss: 2.0358 - val_accuracy: 0.5118 - val_auc: 0.7686\n",
            "Epoch 429/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5584 - accuracy: 0.7628 - auc: 0.9431 - val_loss: 2.0430 - val_accuracy: 0.5061 - val_auc: 0.7680\n",
            "Epoch 430/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5584 - accuracy: 0.7577 - auc: 0.9432 - val_loss: 2.0242 - val_accuracy: 0.5007 - val_auc: 0.7659\n",
            "Epoch 431/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5595 - accuracy: 0.7618 - auc: 0.9428 - val_loss: 2.0383 - val_accuracy: 0.5097 - val_auc: 0.7702\n",
            "Epoch 432/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5565 - accuracy: 0.7645 - auc: 0.9437 - val_loss: 2.0275 - val_accuracy: 0.5109 - val_auc: 0.7725\n",
            "Epoch 433/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5606 - accuracy: 0.7609 - auc: 0.9427 - val_loss: 2.0249 - val_accuracy: 0.5130 - val_auc: 0.7715\n",
            "Epoch 434/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5609 - accuracy: 0.7586 - auc: 0.9425 - val_loss: 2.0354 - val_accuracy: 0.5094 - val_auc: 0.7713\n",
            "Epoch 435/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5582 - accuracy: 0.7606 - auc: 0.9430 - val_loss: 2.0136 - val_accuracy: 0.5094 - val_auc: 0.7679\n",
            "Epoch 436/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5589 - accuracy: 0.7618 - auc: 0.9432 - val_loss: 2.0108 - val_accuracy: 0.5157 - val_auc: 0.7723\n",
            "Epoch 437/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5587 - accuracy: 0.7617 - auc: 0.9432 - val_loss: 2.0750 - val_accuracy: 0.4963 - val_auc: 0.7634\n",
            "Epoch 438/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.5589 - accuracy: 0.7594 - auc: 0.9430 - val_loss: 2.0659 - val_accuracy: 0.5094 - val_auc: 0.7682\n",
            "Epoch 439/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5550 - accuracy: 0.7611 - auc: 0.9439 - val_loss: 2.0262 - val_accuracy: 0.5076 - val_auc: 0.7693\n",
            "Epoch 440/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5566 - accuracy: 0.7607 - auc: 0.9435 - val_loss: 2.0619 - val_accuracy: 0.5136 - val_auc: 0.7690\n",
            "Epoch 441/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5586 - accuracy: 0.7649 - auc: 0.9431 - val_loss: 2.0458 - val_accuracy: 0.4987 - val_auc: 0.7644\n",
            "Epoch 442/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5564 - accuracy: 0.7615 - auc: 0.9437 - val_loss: 2.0483 - val_accuracy: 0.4981 - val_auc: 0.7619\n",
            "Epoch 443/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5560 - accuracy: 0.7635 - auc: 0.9437 - val_loss: 2.0906 - val_accuracy: 0.5052 - val_auc: 0.7667\n",
            "Epoch 444/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5537 - accuracy: 0.7613 - auc: 0.9440 - val_loss: 2.0409 - val_accuracy: 0.5064 - val_auc: 0.7696\n",
            "Epoch 445/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5595 - accuracy: 0.7609 - auc: 0.9430 - val_loss: 2.0716 - val_accuracy: 0.5151 - val_auc: 0.7704\n",
            "Epoch 446/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5558 - accuracy: 0.7628 - auc: 0.9436 - val_loss: 2.0631 - val_accuracy: 0.5232 - val_auc: 0.7754\n",
            "Epoch 447/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5546 - accuracy: 0.7569 - auc: 0.9437 - val_loss: 2.0610 - val_accuracy: 0.5079 - val_auc: 0.7680\n",
            "Epoch 448/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5534 - accuracy: 0.7626 - auc: 0.9442 - val_loss: 2.0624 - val_accuracy: 0.5007 - val_auc: 0.7645\n",
            "Epoch 449/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5571 - accuracy: 0.7621 - auc: 0.9431 - val_loss: 2.0723 - val_accuracy: 0.5004 - val_auc: 0.7645\n",
            "Epoch 450/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5569 - accuracy: 0.7581 - auc: 0.9435 - val_loss: 2.0813 - val_accuracy: 0.5067 - val_auc: 0.7706\n",
            "Epoch 451/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5556 - accuracy: 0.7613 - auc: 0.9438 - val_loss: 2.0719 - val_accuracy: 0.4960 - val_auc: 0.7620\n",
            "Epoch 452/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5531 - accuracy: 0.7661 - auc: 0.9443 - val_loss: 2.0514 - val_accuracy: 0.5079 - val_auc: 0.7687\n",
            "Epoch 453/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5561 - accuracy: 0.7609 - auc: 0.9437 - val_loss: 2.0386 - val_accuracy: 0.5061 - val_auc: 0.7663\n",
            "Epoch 454/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5561 - accuracy: 0.7609 - auc: 0.9436 - val_loss: 2.0898 - val_accuracy: 0.5097 - val_auc: 0.7650\n",
            "Epoch 455/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5573 - accuracy: 0.7599 - auc: 0.9433 - val_loss: 2.0473 - val_accuracy: 0.5022 - val_auc: 0.7696\n",
            "Epoch 456/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.5527 - accuracy: 0.7600 - auc: 0.9442 - val_loss: 2.0461 - val_accuracy: 0.5058 - val_auc: 0.7667\n",
            "Epoch 457/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5552 - accuracy: 0.7605 - auc: 0.9437 - val_loss: 2.0834 - val_accuracy: 0.5052 - val_auc: 0.7659\n",
            "Epoch 458/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5563 - accuracy: 0.7640 - auc: 0.9437 - val_loss: 2.0726 - val_accuracy: 0.5103 - val_auc: 0.7687\n",
            "Epoch 459/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5543 - accuracy: 0.7622 - auc: 0.9437 - val_loss: 2.0714 - val_accuracy: 0.5049 - val_auc: 0.7629\n",
            "Epoch 460/500\n",
            "1003/1003 [==============================] - 2s 2ms/step - loss: 0.5519 - accuracy: 0.7626 - auc: 0.9444 - val_loss: 2.0913 - val_accuracy: 0.5043 - val_auc: 0.7686\n",
            "Epoch 461/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5536 - accuracy: 0.7647 - auc: 0.9441 - val_loss: 2.0922 - val_accuracy: 0.5124 - val_auc: 0.7697\n",
            "Epoch 462/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5551 - accuracy: 0.7633 - auc: 0.9439 - val_loss: 2.0911 - val_accuracy: 0.5034 - val_auc: 0.7672\n",
            "Epoch 463/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5553 - accuracy: 0.7635 - auc: 0.9440 - val_loss: 2.0846 - val_accuracy: 0.5169 - val_auc: 0.7700\n",
            "Epoch 464/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5555 - accuracy: 0.7609 - auc: 0.9437 - val_loss: 2.1004 - val_accuracy: 0.5079 - val_auc: 0.7637\n",
            "Epoch 465/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.5564 - accuracy: 0.7627 - auc: 0.9437 - val_loss: 2.0695 - val_accuracy: 0.5097 - val_auc: 0.7700\n",
            "Epoch 466/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5539 - accuracy: 0.7612 - auc: 0.9440 - val_loss: 2.1129 - val_accuracy: 0.5046 - val_auc: 0.7669\n",
            "Epoch 467/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.5540 - accuracy: 0.7636 - auc: 0.9440 - val_loss: 2.1080 - val_accuracy: 0.5064 - val_auc: 0.7650\n",
            "Epoch 468/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5563 - accuracy: 0.7638 - auc: 0.9437 - val_loss: 2.1112 - val_accuracy: 0.5043 - val_auc: 0.7659\n",
            "Epoch 469/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5543 - accuracy: 0.7630 - auc: 0.9440 - val_loss: 2.1137 - val_accuracy: 0.5040 - val_auc: 0.7655\n",
            "Epoch 470/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5555 - accuracy: 0.7614 - auc: 0.9436 - val_loss: 2.0628 - val_accuracy: 0.5139 - val_auc: 0.7683\n",
            "Epoch 471/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5510 - accuracy: 0.7656 - auc: 0.9444 - val_loss: 2.0803 - val_accuracy: 0.5070 - val_auc: 0.7700\n",
            "Epoch 472/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5563 - accuracy: 0.7582 - auc: 0.9434 - val_loss: 2.1164 - val_accuracy: 0.5019 - val_auc: 0.7671\n",
            "Epoch 473/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5545 - accuracy: 0.7624 - auc: 0.9439 - val_loss: 2.1231 - val_accuracy: 0.4966 - val_auc: 0.7623\n",
            "Epoch 474/500\n",
            "1003/1003 [==============================] - 4s 4ms/step - loss: 0.5500 - accuracy: 0.7652 - auc: 0.9449 - val_loss: 2.0963 - val_accuracy: 0.5025 - val_auc: 0.7690\n",
            "Epoch 475/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5542 - accuracy: 0.7625 - auc: 0.9438 - val_loss: 2.0963 - val_accuracy: 0.5007 - val_auc: 0.7624\n",
            "Epoch 476/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5508 - accuracy: 0.7629 - auc: 0.9445 - val_loss: 2.1084 - val_accuracy: 0.5010 - val_auc: 0.7653\n",
            "Epoch 477/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5539 - accuracy: 0.7626 - auc: 0.9440 - val_loss: 2.0782 - val_accuracy: 0.5070 - val_auc: 0.7692\n",
            "Epoch 478/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5528 - accuracy: 0.7644 - auc: 0.9443 - val_loss: 2.1328 - val_accuracy: 0.5100 - val_auc: 0.7670\n",
            "Epoch 479/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5522 - accuracy: 0.7659 - auc: 0.9445 - val_loss: 2.0885 - val_accuracy: 0.5058 - val_auc: 0.7689\n",
            "Epoch 480/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5532 - accuracy: 0.7657 - auc: 0.9442 - val_loss: 2.1175 - val_accuracy: 0.5097 - val_auc: 0.7682\n",
            "Epoch 481/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5504 - accuracy: 0.7611 - auc: 0.9444 - val_loss: 2.1123 - val_accuracy: 0.5007 - val_auc: 0.7654\n",
            "Epoch 482/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5491 - accuracy: 0.7672 - auc: 0.9452 - val_loss: 2.1193 - val_accuracy: 0.5070 - val_auc: 0.7672\n",
            "Epoch 483/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5591 - accuracy: 0.7586 - auc: 0.9430 - val_loss: 2.1280 - val_accuracy: 0.5079 - val_auc: 0.7674\n",
            "Epoch 484/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5512 - accuracy: 0.7636 - auc: 0.9446 - val_loss: 2.1254 - val_accuracy: 0.4996 - val_auc: 0.7653\n",
            "Epoch 485/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5527 - accuracy: 0.7634 - auc: 0.9442 - val_loss: 2.1024 - val_accuracy: 0.5139 - val_auc: 0.7677\n",
            "Epoch 486/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5562 - accuracy: 0.7634 - auc: 0.9436 - val_loss: 2.1372 - val_accuracy: 0.4984 - val_auc: 0.7638\n",
            "Epoch 487/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5505 - accuracy: 0.7631 - auc: 0.9447 - val_loss: 2.1141 - val_accuracy: 0.5085 - val_auc: 0.7677\n",
            "Epoch 488/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5517 - accuracy: 0.7656 - auc: 0.9446 - val_loss: 2.1279 - val_accuracy: 0.5085 - val_auc: 0.7668\n",
            "Epoch 489/500\n",
            "1003/1003 [==============================] - 3s 2ms/step - loss: 0.5519 - accuracy: 0.7619 - auc: 0.9442 - val_loss: 2.1406 - val_accuracy: 0.5061 - val_auc: 0.7689\n",
            "Epoch 490/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5498 - accuracy: 0.7618 - auc: 0.9449 - val_loss: 2.1482 - val_accuracy: 0.4999 - val_auc: 0.7615\n",
            "Epoch 491/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5497 - accuracy: 0.7625 - auc: 0.9449 - val_loss: 2.1521 - val_accuracy: 0.4981 - val_auc: 0.7626\n",
            "Epoch 492/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5528 - accuracy: 0.7678 - auc: 0.9445 - val_loss: 2.1320 - val_accuracy: 0.5067 - val_auc: 0.7658\n",
            "Epoch 493/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5506 - accuracy: 0.7671 - auc: 0.9446 - val_loss: 2.1499 - val_accuracy: 0.5145 - val_auc: 0.7697\n",
            "Epoch 494/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5517 - accuracy: 0.7609 - auc: 0.9443 - val_loss: 2.1638 - val_accuracy: 0.5013 - val_auc: 0.7618\n",
            "Epoch 495/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5483 - accuracy: 0.7636 - auc: 0.9451 - val_loss: 2.1222 - val_accuracy: 0.5031 - val_auc: 0.7644\n",
            "Epoch 496/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5487 - accuracy: 0.7666 - auc: 0.9450 - val_loss: 2.1672 - val_accuracy: 0.5061 - val_auc: 0.7675\n",
            "Epoch 497/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5484 - accuracy: 0.7670 - auc: 0.9451 - val_loss: 2.1339 - val_accuracy: 0.5010 - val_auc: 0.7646\n",
            "Epoch 498/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5531 - accuracy: 0.7667 - auc: 0.9441 - val_loss: 2.1482 - val_accuracy: 0.5100 - val_auc: 0.7664\n",
            "Epoch 499/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5479 - accuracy: 0.7658 - auc: 0.9451 - val_loss: 2.1548 - val_accuracy: 0.5121 - val_auc: 0.7675\n",
            "Epoch 500/500\n",
            "1003/1003 [==============================] - 3s 3ms/step - loss: 0.5489 - accuracy: 0.7643 - auc: 0.9449 - val_loss: 2.1746 - val_accuracy: 0.5127 - val_auc: 0.7662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.params)\n",
        "plt.plot(history.history['auc'])\n",
        "#blue is AUC\n",
        "plt.plot(history.history['accuracy'])\n",
        "#orange is Accuracy\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "EA8G6ySnN-B7",
        "outputId": "97fc9d60-69ab-4d38-b217-3d0747c2a081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': 1, 'epochs': 500, 'steps': 1003}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_weights('best_model.hdf5')\n",
        "\n",
        "scores = model.evaluate(X_train,y_train)\n",
        "print(model.metrics_names)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vQoTGZCOV92",
        "outputId": "f41959ec-1e88-4e5b-d6ed-7e499690165d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314/314 [==============================] - 1s 2ms/step - loss: 0.5590 - accuracy: 0.7652\n",
            "['loss', 'accuracy']\n",
            "[0.5590354204177856, 0.765239953994751]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scores = model.evaluate(X_train, y_train)\n",
        "print(model.metrics_names)\n",
        "print(scores)\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "print(model.metrics_names)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSihtqJuOsMD",
        "outputId": "7c3e09b0-73e7-48e2-bbf5-d0369e023b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314/314 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7652\n",
            "['loss', 'accuracy']\n",
            "[0.5590354204177856, 0.765239953994751]\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 1.7357 - accuracy: 0.5061\n",
            "['loss', 'accuracy']\n",
            "[1.735695719718933, 0.506135880947113]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_test\")\n",
        "print(X_test[40:50])\n",
        "print(\"y_test\")\n",
        "print(y_test[40:50])\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "print(\"prediction\")\n",
        "print(prediction[40:50])\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_test,prediction)\n",
        "print(mse)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMT7zeV4-8gp",
        "outputId": "0e3c11ce-6e0e-407b-951c-addb7d93f57f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test\n",
            "[[-0.32 -1.11 -1.25  0.05  0.02 -0.55  0.31 -2.13 -0.06 -0.46 -0.29 -0.96\n",
            "   2.05 -0.29  1.02 -1.02  0.92 -0.28 -0.33 -0.17 -0.47 -0.29]\n",
            " [ 0.37  1.66  0.03 -0.89 -0.4  -0.63  0.22 -0.74 -0.05 -0.46 -0.29  1.04\n",
            "  -0.49 -0.29  1.02 -1.02  0.92 -0.28 -0.33 -0.17 -0.47 -0.29]\n",
            " [-1.71  0.93 -0.68 -1.54 -1.74 -0.37  1.19 -0.54 -0.94 -0.46 -0.29 -0.96\n",
            "   2.05 -0.29 -0.98  0.98 -1.09 -0.28  3.01 -0.17 -0.47 -0.29]\n",
            " [ 1.57 -0.09  0.3  -1.59 -1.86  0.42 -1.47 -0.69  0.99 -0.46 -0.29  1.04\n",
            "  -0.49 -0.29 -0.98  0.98  0.92 -0.28 -0.33 -0.17 -0.47 -0.29]\n",
            " [ 1.34 -0.88  1.17  0.27  0.43 -0.63 -0.1  -0.28  1.19 -0.46 -0.29  1.04\n",
            "  -0.49 -0.29  1.02 -1.02  0.92 -0.28 -0.33 -0.17 -0.47 -0.29]\n",
            " [ 0.71  1.43 -0.03  0.94  0.61 -0.63  0.83  0.69 -0.58 -0.46 -0.29 -0.96\n",
            "   2.05 -0.29 -0.98  0.98  0.92 -0.28 -0.33 -0.17 -0.47 -0.29]\n",
            " [-1.74 -0.6   1.41 -1.1  -0.95 -0.41 -0.14  1.36 -0.02 -0.46 -0.29  1.04\n",
            "  -0.49 -0.29  1.02 -1.02 -1.09 -0.28 -0.33 -0.17  2.11 -0.29]\n",
            " [ 0.04 -1.11 -0.39  1.75  2.01  2.01 -0.39 -0.79  1.46 -0.46 -0.29  1.04\n",
            "  -0.49 -0.29 -0.98  0.98  0.92 -0.28 -0.33 -0.17 -0.47 -0.29]\n",
            " [ 0.14  0.64 -0.69 -0.55 -0.49 -0.63 -0.53  0.64 -0.76  2.15 -0.29 -0.96\n",
            "  -0.49 -0.29  1.02 -1.02  0.92 -0.28 -0.33 -0.17 -0.47 -0.29]\n",
            " [-0.07 -0.94 -0.46 -0.81 -0.21 -0.63  0.29  1.1   1.29 -0.46 -0.29  1.04\n",
            "  -0.49 -0.29  1.02 -1.02 -1.09 -0.28 -0.33  5.91 -0.47 -0.29]]\n",
            "y_test\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "105/105 [==============================] - 0s 2ms/step\n",
            "prediction\n",
            "[[7.69e-01 2.31e-01 2.30e-09 3.84e-12]\n",
            " [5.60e-02 6.23e-01 1.25e-01 1.96e-01]\n",
            " [8.97e-01 1.02e-01 5.43e-05 5.19e-04]\n",
            " [9.22e-01 7.85e-02 5.47e-07 1.84e-09]\n",
            " [7.61e-01 2.38e-01 1.45e-03 5.68e-13]\n",
            " [5.80e-02 2.02e-01 5.93e-02 6.80e-01]\n",
            " [9.28e-01 6.15e-02 1.05e-02 1.84e-07]\n",
            " [2.15e-01 7.85e-01 1.03e-08 5.26e-08]\n",
            " [4.19e-01 5.16e-01 3.96e-05 6.49e-02]\n",
            " [6.49e-01 3.51e-01 1.52e-07 1.78e-12]]\n",
            "0.17600596\n"
          ]
        }
      ]
    }
  ]
}